{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# SLEAP Distance Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4546bee655b14a5dbf393161f1228e60",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Brief 1-2 sentence description of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import git\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import savgol_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "git_repo = git.Repo(\".\", search_parent_directories=True)\n",
    "git_root = git_repo.git.rev_parse(\"--show-toplevel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/blue/npadillacoreano/ryoi360/projects/reward_comp/repos/reward_competition_extention'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(git_root, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import utilities.helper\n",
    "import sleap.process_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sns.set('notebook', 'ticks', font_scale=1.2)\n",
    "mpl.rcParams['figure.figsize'] = [15,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_velocity(node_loc, window_size=25, polynomial_order=3):\n",
    "    \"\"\"\n",
    "    Calculate the velocity of tracked nodes from pose data.\n",
    "    \n",
    "    The function utilizes the Savitzky-Golay filter to smooth the data and compute the velocity.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    node_loc : numpy.ndarray\n",
    "        The location of nodes, represented as an array of shape [frames, 2]. \n",
    "        Each row represents x and y coordinates for a particular frame.\n",
    "        \n",
    "    window_size : int, optional\n",
    "        The size of the window used for the Savitzky-Golay filter. \n",
    "        Represents the number of consecutive data points used when smoothing the data.\n",
    "        Default is 25.\n",
    "        \n",
    "    polynomial_order : int, optional\n",
    "        The order of the polynomial fit to the data within the Savitzky-Golay filter window.\n",
    "        Default is 3.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        The velocity for each frame, calculated from the smoothed x and y coordinates.\n",
    "    \n",
    "    \"\"\"\n",
    "    node_loc_vel = np.zeros_like(node_loc)\n",
    "    \n",
    "    # For each coordinate (x and y), smooth the data and calculate the derivative (velocity)\n",
    "    for c in range(node_loc.shape[-1]):\n",
    "        node_loc_vel[:, c] = savgol_filter(node_loc[:, c], window_size, polynomial_order, deriv=1)\n",
    "    \n",
    "    # Calculate the magnitude of the velocity vectors for each frame\n",
    "    node_vel = np.linalg.norm(node_loc_vel, axis=1)\n",
    "\n",
    "    return node_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rolling_average(arr, window_size):\n",
    "    \"\"\"\n",
    "    Computes the rolling average using a specified window size.\n",
    "    \n",
    "    Parameters:\n",
    "        arr (numpy.array): The input array to compute the rolling average for.\n",
    "        window_size (int): The size of the rolling window.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: The rolling average of the input array.\n",
    "    \"\"\"\n",
    "    if window_size < 1:\n",
    "       raise ValueError(\"Window size must be at least 1.\")\n",
    "    \n",
    "    # Create a uniform window of given window size\n",
    "    window = np.ones(window_size) / window_size\n",
    "\n",
    "    # Use numpy's convolve function to compute the rolling average\n",
    "    return np.convolve(arr, window, mode='valid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunked_average(arr, chunk_size):\n",
    "    \"\"\"\n",
    "    Computes the average for non-overlapping chunks of the input array.\n",
    "    \n",
    "    Parameters:\n",
    "        arr (numpy.array): The input array.\n",
    "        chunk_size (int): The size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: The averages of the non-overlapping chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of chunks\n",
    "    num_chunks = len(arr) // chunk_size\n",
    "    \n",
    "    # Reshape the array into a 2D array of shape (num_chunks, chunk_size)\n",
    "    reshaped_arr = arr[:num_chunks * chunk_size].reshape(num_chunks, chunk_size)\n",
    "    \n",
    "    # Compute the mean along the second axis (i.e., for each chunk)\n",
    "    return reshaped_arr.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sliding_window_average(arr, window_size, step=1):\n",
    "    \"\"\"\n",
    "    Apply a sliding window to a 1D numpy array, returning the average of windows of a specified size.\n",
    "\n",
    "    :param arr: Input 1D numpy array.\n",
    "    :param window_size: Size of the window.\n",
    "    :param step: The step size or number of elements to slide the window by. Default is 1.\n",
    "    :return: A 1D numpy array where each element is the average of a window from the input.\n",
    "    \"\"\"\n",
    "    # Number of windows\n",
    "    num_windows = ((arr.size - window_size) // step) + 1\n",
    "    \n",
    "    # Output array for averages\n",
    "    averages = np.zeros(num_windows)\n",
    "    \n",
    "    for i in range(num_windows):\n",
    "        # Calculate the start and end index for the window\n",
    "        start = i * step\n",
    "        end = start + window_size\n",
    "        # Calculate the average of the window\n",
    "        averages[i] = np.mean(arr[start:end])\n",
    "\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_all_window_indices(original_index, window_size, step, array_length):\n",
    "    \"\"\"\n",
    "    Calculate all the start and stop indices for sliding windows based on an original start index.\n",
    "\n",
    "    :param original_index: The original index from which the first window should start.\n",
    "    :param window_size: The size of each sliding window.\n",
    "    :param step: The step size or number of elements to slide the window by.\n",
    "    :param array_length: The total number of elements in the array.\n",
    "    :return: A list of tuples, each containing the start and stop indices for a sliding window.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the list to hold the start and stop indices for all windows\n",
    "    windows = []\n",
    "\n",
    "    # Initialize the current start index with the original index\n",
    "    current_start_index = original_index\n",
    "\n",
    "    # Loop through the array until the end is reached\n",
    "    while current_start_index + window_size <= original_index + array_length:\n",
    "        # Calculate the stop index based on the window size\n",
    "        stop_index = current_start_index + window_size\n",
    "\n",
    "        # Add the start and stop indices to the list\n",
    "        windows.append((current_start_index, stop_index))\n",
    "\n",
    "        # Update the current start index by adding the step size\n",
    "        current_start_index += step\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "THORAX_INDEX = 1\n",
    "\n",
    "# VIDEO_TO_FRAME_AND_SUBJECT_DF[\"video_name\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"video_name\"].apply(lambda x: x.strip(\".videoTimeStamps.cameraHWSync\"))\n",
    "\n",
    "# SLEAP_DIR = os.path.join(git_root, \"proc/sleap\") \n",
    "# SLEAP_DIR = \"/scratch/back_up/reward_competition_extention/final_proc/id_corrected\"\n",
    "SLEAP_DIR = \"/blue/npadillacoreano/ryoi360/projects/reward_comp/final_proc/id_corrected\"\n",
    "\n",
    "OUTPUT_DIR = r\"./proc\" # where data is saved should always be shown in the inputs\n",
    "MED_PC_WIDTH = 29.5\n",
    "MED_PC_HEIGHT = 24\n",
    "FRAME_RATE = 22\n",
    "WINDOW_SIZE = 25\n",
    "DISTANCE_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = pd.read_excel(\"./data/rce_per_subject_start_stop_video_frame.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_PREFIX = \"rce_pilot_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FULL_LFP_TRACES_PKL = \"{}_full_spectral_and_sleap_poses.pkl\".format(OUTPUT_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the videos where the subject is in the recording"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at when each subject was in each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = pd.read_excel(\"./data/rce_per_subject_start_stop_video_frame.xlsx\")\n",
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.dropna(subset=[\"file_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the name of the SLEAP and video files where each subject was in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"sleap_name\"] = START_STOP_FRAME_DF[\"file_path\"].apply(lambda x: os.path.basename(x))\n",
    "START_STOP_FRAME_DF[\"video_name\"] = START_STOP_FRAME_DF[\"file_path\"].apply(lambda x: \".\".join(os.path.basename(x).split(\".\")[:2]))\n",
    "START_STOP_FRAME_DF[\"start_frame\"] = START_STOP_FRAME_DF[\"start_frame\"].astype(int)\n",
    "START_STOP_FRAME_DF[\"stop_frame\"] = START_STOP_FRAME_DF[\"stop_frame\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.drop(columns=[\"file_path\", \"notes\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20221214_125409_om_and_comp_6_1_and_6_3.1',\n",
       "       '20221215_145401_comp_amd_om_6_1_and_6_3.1',\n",
       "       '20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.1',\n",
       "       '20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.2',\n",
       "       '20230613_105657_standard_comp_to_training_D2_subj_1-1_and_1-4.1',\n",
       "       '20230613_105657_standard_comp_to_training_D2_subj_1-1_and_1-4.2',\n",
       "       '20230614_114041_standard_comp_to_training_D3_subj_1-1_and_1-2.1',\n",
       "       '20230614_114041_standard_comp_to_training_D3_subj_1-1_and_1-2.2',\n",
       "       '20230614_114041_standard_comp_to_training_D3_subj_1-1_and_1-2.3',\n",
       "       '20230616_111904_standard_comp_to_training_D4_subj_1-4_and_1-2.1',\n",
       "       '20230616_111904_standard_comp_to_training_D4_subj_1-4_and_1-2.2',\n",
       "       '20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2.1',\n",
       "       '20230617_115521_standard_comp_to_omission_D1_subj_1-1_and_1-2.3',\n",
       "       '20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1.1',\n",
       "       '20230618_100636_standard_comp_to_omission_D2_subj_1-4_and_1-1.2',\n",
       "       '20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4.3',\n",
       "       '20230619_115321_standard_comp_to_omission_D3_subj_1-2_and_1-4.4',\n",
       "       '20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1.1',\n",
       "       '20230620_114347_standard_comp_to_omission_D4_subj_1-2_and_1-1.2',\n",
       "       '20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2.1',\n",
       "       '20230621_111240_standard_comp_to_omission_D5_subj_1-4_and_1-2.2',\n",
       "       '20230622_110832_standard_comp_to_both_rewarded_D1_subj_1-1_and_1-2.1',\n",
       "       '20230623_114932_standard_comp_to_both_rewarded_D2_subj_1-4_and_1-1.1',\n",
       "       '20230623_114932_standard_comp_to_both_rewarded_D2_subj_1-4_and_1-1.2',\n",
       "       '20230624_105855_standard_comp_to_both_rewarded_D3_subj_1-2_and_1-4.1',\n",
       "       '20230625_112913_standard_comp_to_both_rewarded_D4_subj_1-1_and_1-4.1',\n",
       "       '20230628_111202_standard_comp_to_novel_agent_D1_subj_1-1vs2-2and1-2vs2-1.1',\n",
       "       '20230628_111202_standard_comp_to_novel_agent_D1_subj_1-1vs2-2and1-2vs2-1.2',\n",
       "       '20230628_111202_standard_comp_to_novel_agent_D1_subj_1-1vs2-2and1-2vs2-1.3',\n",
       "       '20230628_111202_standard_comp_to_novel_agent_D1_subj_1-1vs2-2and1-2vs2-1.4',\n",
       "       '20230629_111937_standard_comp_to_novel_agent_D2_subj_1-1vs2-1and1-4vs2-2.1',\n",
       "       '20230629_111937_standard_comp_to_novel_agent_D2_subj_1-1vs2-1and1-4vs2-2.2',\n",
       "       '20230630_115506_standard_comp_to_novel_agent_D3_subj_1-4vs2-1and1-2vs2-2.1',\n",
       "       '20230630_115506_standard_comp_to_novel_agent_D3_subj_1-4vs2-1and1-2vs2-2.2'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"video_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_frame</th>\n",
       "      <th>stop_frame</th>\n",
       "      <th>tracked_subject</th>\n",
       "      <th>in_video_subjects</th>\n",
       "      <th>box_number</th>\n",
       "      <th>sleap_name</th>\n",
       "      <th>video_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20221214_125409_om_and_comp_6_1_and_6_3.1.fixe...</td>\n",
       "      <td>20221214_125409_om_and_comp_6_1_and_6_3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27500</td>\n",
       "      <td>73600</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20221214_125409_om_and_comp_6_1_and_6_3.1.fixe...</td>\n",
       "      <td>20221214_125409_om_and_comp_6_1_and_6_3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51500</td>\n",
       "      <td>76454</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20221215_145401_comp_amd_om_6_1_and_6_3.1.fixe...</td>\n",
       "      <td>20221215_145401_comp_amd_om_6_1_and_6_3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>48500</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20221215_145401_comp_amd_om_6_1_and_6_3.1.fixe...</td>\n",
       "      <td>20221215_145401_comp_amd_om_6_1_and_6_3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32700</td>\n",
       "      <td>68257</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1_1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_frame  stop_frame tracked_subject in_video_subjects  box_number  \\\n",
       "0            1       25000             6.3           6.1_6.3           1   \n",
       "1        27500       73600         6.1_6.3           6.1_6.3           1   \n",
       "2        51500       76454             6.3           6.1_6.3           1   \n",
       "3            1       48500         6.1_6.3           6.1_6.3           1   \n",
       "4        32700       68257             1.2           1.1_1.2           1   \n",
       "\n",
       "                                          sleap_name  \\\n",
       "0  20221214_125409_om_and_comp_6_1_and_6_3.1.fixe...   \n",
       "1  20221214_125409_om_and_comp_6_1_and_6_3.1.fixe...   \n",
       "2  20221215_145401_comp_amd_om_6_1_and_6_3.1.fixe...   \n",
       "3  20221215_145401_comp_amd_om_6_1_and_6_3.1.fixe...   \n",
       "4  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "\n",
       "                                          video_name  \n",
       "0          20221214_125409_om_and_comp_6_1_and_6_3.1  \n",
       "1          20221214_125409_om_and_comp_6_1_and_6_3.1  \n",
       "2          20221215_145401_comp_amd_om_6_1_and_6_3.1  \n",
       "3          20221215_145401_comp_amd_om_6_1_and_6_3.1  \n",
       "4  20230612_112630_standard_comp_to_training_D1_s...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting each row into seperate row for each subject in the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"tracked_subject\"] = START_STOP_FRAME_DF[\"tracked_subject\"].apply(lambda x: str(x).split(\"_\"))\n",
    "START_STOP_FRAME_DF[\"current_subject\"] = START_STOP_FRAME_DF[\"tracked_subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.explode(\"current_subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_frame</th>\n",
       "      <th>stop_frame</th>\n",
       "      <th>tracked_subject</th>\n",
       "      <th>in_video_subjects</th>\n",
       "      <th>box_number</th>\n",
       "      <th>sleap_name</th>\n",
       "      <th>video_name</th>\n",
       "      <th>current_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25000</td>\n",
       "      <td>[6.3]</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20221214_125409_om_and_comp_6_1_and_6_3.1.fixe...</td>\n",
       "      <td>20221214_125409_om_and_comp_6_1_and_6_3.1</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27500</td>\n",
       "      <td>73600</td>\n",
       "      <td>[6.1, 6.3]</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20221214_125409_om_and_comp_6_1_and_6_3.1.fixe...</td>\n",
       "      <td>20221214_125409_om_and_comp_6_1_and_6_3.1</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27500</td>\n",
       "      <td>73600</td>\n",
       "      <td>[6.1, 6.3]</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20221214_125409_om_and_comp_6_1_and_6_3.1.fixe...</td>\n",
       "      <td>20221214_125409_om_and_comp_6_1_and_6_3.1</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51500</td>\n",
       "      <td>76454</td>\n",
       "      <td>[6.3]</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20221215_145401_comp_amd_om_6_1_and_6_3.1.fixe...</td>\n",
       "      <td>20221215_145401_comp_amd_om_6_1_and_6_3.1</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>48500</td>\n",
       "      <td>[6.1, 6.3]</td>\n",
       "      <td>6.1_6.3</td>\n",
       "      <td>1</td>\n",
       "      <td>20221215_145401_comp_amd_om_6_1_and_6_3.1.fixe...</td>\n",
       "      <td>20221215_145401_comp_amd_om_6_1_and_6_3.1</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_frame  stop_frame tracked_subject in_video_subjects  box_number  \\\n",
       "0            1       25000           [6.3]           6.1_6.3           1   \n",
       "1        27500       73600      [6.1, 6.3]           6.1_6.3           1   \n",
       "1        27500       73600      [6.1, 6.3]           6.1_6.3           1   \n",
       "2        51500       76454           [6.3]           6.1_6.3           1   \n",
       "3            1       48500      [6.1, 6.3]           6.1_6.3           1   \n",
       "\n",
       "                                          sleap_name  \\\n",
       "0  20221214_125409_om_and_comp_6_1_and_6_3.1.fixe...   \n",
       "1  20221214_125409_om_and_comp_6_1_and_6_3.1.fixe...   \n",
       "1  20221214_125409_om_and_comp_6_1_and_6_3.1.fixe...   \n",
       "2  20221215_145401_comp_amd_om_6_1_and_6_3.1.fixe...   \n",
       "3  20221215_145401_comp_amd_om_6_1_and_6_3.1.fixe...   \n",
       "\n",
       "                                  video_name current_subject  \n",
       "0  20221214_125409_om_and_comp_6_1_and_6_3.1             6.3  \n",
       "1  20221214_125409_om_and_comp_6_1_and_6_3.1             6.1  \n",
       "1  20221214_125409_om_and_comp_6_1_and_6_3.1             6.3  \n",
       "2  20221215_145401_comp_amd_om_6_1_and_6_3.1             6.3  \n",
       "3  20221215_145401_comp_amd_om_6_1_and_6_3.1             6.1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the h5 files between recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"sleap_glob\"] = START_STOP_FRAME_DF[\"sleap_name\"].apply(lambda x: glob.glob(os.path.join(SLEAP_DIR, \"**\", x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230614_114041_standard_comp_to_training_D3_subj_1-1_and_1-2.1.2_subj.id_corrected.h5'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"sleap_name\"].iloc[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF[START_STOP_FRAME_DF['sleap_glob'].apply(lambda x: len(x) >= 1)]\n",
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"sleap_path\"] = START_STOP_FRAME_DF[\"sleap_glob\"].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"all_sleap_data\"] = START_STOP_FRAME_DF[\"sleap_path\"].apply(lambda x: sleap.process_pose.extract_sleap_data(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"body_parts\"] = START_STOP_FRAME_DF[\"sleap_path\"].apply(lambda x: sleap.process_pose.get_node_names_from_sleap(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['left_ear', 'right_ear', 'nose', 'tail_base', 'thorax', 'forehead']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"body_parts\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"locations\"] = START_STOP_FRAME_DF[\"all_sleap_data\"].apply(lambda x: x[\"locations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"track_names\"] = START_STOP_FRAME_DF[\"all_sleap_data\"].apply(lambda x: x[\"track_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68258, 6, 2, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"locations\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_frame</th>\n",
       "      <th>stop_frame</th>\n",
       "      <th>tracked_subject</th>\n",
       "      <th>in_video_subjects</th>\n",
       "      <th>box_number</th>\n",
       "      <th>sleap_name</th>\n",
       "      <th>video_name</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>sleap_glob</th>\n",
       "      <th>sleap_path</th>\n",
       "      <th>all_sleap_data</th>\n",
       "      <th>body_parts</th>\n",
       "      <th>locations</th>\n",
       "      <th>track_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32700</td>\n",
       "      <td>68257</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>1.1_1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>[/blue/npadillacoreano/ryoi360/projects/reward...</td>\n",
       "      <td>/blue/npadillacoreano/ryoi360/projects/reward_...</td>\n",
       "      <td>{'locations': [[[[244.3555603 ]\n",
       " [395.80090332...</td>\n",
       "      <td>[left_ear, right_ear, nose, tail_base, thorax,...</td>\n",
       "      <td>[[[[244.3555603], [395.80090332]], [[247.78367...</td>\n",
       "      <td>[1.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32300</td>\n",
       "      <td>[1.1, 1.2]</td>\n",
       "      <td>1.1_1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>[/blue/npadillacoreano/ryoi360/projects/reward...</td>\n",
       "      <td>/blue/npadillacoreano/ryoi360/projects/reward_...</td>\n",
       "      <td>{'locations': [[[[331.99508667 244.3555603 ]\n",
       " ...</td>\n",
       "      <td>[left_ear, right_ear, nose, tail_base, thorax,...</td>\n",
       "      <td>[[[[331.99508667 244.3555603 ], [127.74658203 ...</td>\n",
       "      <td>[1.1, 1.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32300</td>\n",
       "      <td>[1.1, 1.2]</td>\n",
       "      <td>1.1_1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>[/blue/npadillacoreano/ryoi360/projects/reward...</td>\n",
       "      <td>/blue/npadillacoreano/ryoi360/projects/reward_...</td>\n",
       "      <td>{'locations': [[[[331.99508667 244.3555603 ]\n",
       " ...</td>\n",
       "      <td>[left_ear, right_ear, nose, tail_base, thorax,...</td>\n",
       "      <td>[[[[331.99508667 244.3555603 ], [127.74658203 ...</td>\n",
       "      <td>[1.1, 1.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33000</td>\n",
       "      <td>68212</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>1.1_1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>[/blue/npadillacoreano/ryoi360/projects/reward...</td>\n",
       "      <td>/blue/npadillacoreano/ryoi360/projects/reward_...</td>\n",
       "      <td>{'locations': [[[[nan]\n",
       " [nan]], [[nan]\n",
       " [nan]]...</td>\n",
       "      <td>[left_ear, right_ear, nose, tail_base, thorax,...</td>\n",
       "      <td>[[[[nan], [nan]], [[nan], [nan]], [[nan], [nan...</td>\n",
       "      <td>[1.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33400</td>\n",
       "      <td>68332</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>1.1_1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>[/blue/npadillacoreano/ryoi360/projects/reward...</td>\n",
       "      <td>/blue/npadillacoreano/ryoi360/projects/reward_...</td>\n",
       "      <td>{'locations': [[[[336.33197021]\n",
       " [400.23355103...</td>\n",
       "      <td>[left_ear, right_ear, nose, tail_base, thorax,...</td>\n",
       "      <td>[[[[336.33197021], [400.23355103]], [[319.3523...</td>\n",
       "      <td>[1.1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_frame  stop_frame tracked_subject in_video_subjects  box_number  \\\n",
       "0        32700       68257           [1.2]           1.1_1.2           1   \n",
       "1            1       32300      [1.1, 1.2]           1.1_1.2           1   \n",
       "2            1       32300      [1.1, 1.2]           1.1_1.2           1   \n",
       "3        33000       68212           [1.1]           1.1_1.2           2   \n",
       "4        33400       68332           [1.1]           1.1_1.4           1   \n",
       "\n",
       "                                          sleap_name  \\\n",
       "0  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "1  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "2  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "3  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "4  20230613_105657_standard_comp_to_training_D2_s...   \n",
       "\n",
       "                                          video_name current_subject  \\\n",
       "0  20230612_112630_standard_comp_to_training_D1_s...             1.2   \n",
       "1  20230612_112630_standard_comp_to_training_D1_s...             1.1   \n",
       "2  20230612_112630_standard_comp_to_training_D1_s...             1.2   \n",
       "3  20230612_112630_standard_comp_to_training_D1_s...             1.1   \n",
       "4  20230613_105657_standard_comp_to_training_D2_s...             1.1   \n",
       "\n",
       "                                          sleap_glob  \\\n",
       "0  [/blue/npadillacoreano/ryoi360/projects/reward...   \n",
       "1  [/blue/npadillacoreano/ryoi360/projects/reward...   \n",
       "2  [/blue/npadillacoreano/ryoi360/projects/reward...   \n",
       "3  [/blue/npadillacoreano/ryoi360/projects/reward...   \n",
       "4  [/blue/npadillacoreano/ryoi360/projects/reward...   \n",
       "\n",
       "                                          sleap_path  \\\n",
       "0  /blue/npadillacoreano/ryoi360/projects/reward_...   \n",
       "1  /blue/npadillacoreano/ryoi360/projects/reward_...   \n",
       "2  /blue/npadillacoreano/ryoi360/projects/reward_...   \n",
       "3  /blue/npadillacoreano/ryoi360/projects/reward_...   \n",
       "4  /blue/npadillacoreano/ryoi360/projects/reward_...   \n",
       "\n",
       "                                      all_sleap_data  \\\n",
       "0  {'locations': [[[[244.3555603 ]\n",
       " [395.80090332...   \n",
       "1  {'locations': [[[[331.99508667 244.3555603 ]\n",
       " ...   \n",
       "2  {'locations': [[[[331.99508667 244.3555603 ]\n",
       " ...   \n",
       "3  {'locations': [[[[nan]\n",
       " [nan]], [[nan]\n",
       " [nan]]...   \n",
       "4  {'locations': [[[[336.33197021]\n",
       " [400.23355103...   \n",
       "\n",
       "                                          body_parts  \\\n",
       "0  [left_ear, right_ear, nose, tail_base, thorax,...   \n",
       "1  [left_ear, right_ear, nose, tail_base, thorax,...   \n",
       "2  [left_ear, right_ear, nose, tail_base, thorax,...   \n",
       "3  [left_ear, right_ear, nose, tail_base, thorax,...   \n",
       "4  [left_ear, right_ear, nose, tail_base, thorax,...   \n",
       "\n",
       "                                           locations track_names  \n",
       "0  [[[[244.3555603], [395.80090332]], [[247.78367...       [1.2]  \n",
       "1  [[[[331.99508667 244.3555603 ], [127.74658203 ...  [1.1, 1.2]  \n",
       "2  [[[[331.99508667 244.3555603 ], [127.74658203 ...  [1.1, 1.2]  \n",
       "3  [[[[nan], [nan]], [[nan], [nan]], [[nan], [nan...       [1.1]  \n",
       "4  [[[[336.33197021], [400.23355103]], [[319.3523...       [1.1]  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the indexes of each subject from the track list\n",
    "START_STOP_FRAME_DF[\"subject_to_index\"] = START_STOP_FRAME_DF.apply(lambda x: {k: x[\"track_names\"].index(k) for k in x[\"tracked_subject\"] if k in x[\"track_names\"]}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              {'1.2': 0}\n",
       "1    {'1.1': 0, '1.2': 1}\n",
       "2    {'1.1': 0, '1.2': 1}\n",
       "3              {'1.1': 0}\n",
       "4              {'1.1': 0}\n",
       "Name: subject_to_index, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_index\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"] = START_STOP_FRAME_DF.apply(lambda x: {k:v for k, v in x[\"subject_to_index\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"] = START_STOP_FRAME_DF.apply(lambda x: {k: x[\"locations\"][:,:,:,v] for k, v in x[\"subject_to_index\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'1.2': [[[244.3555603  395.80090332], [247.78...\n",
       "1    {'1.1': [[[331.99508667 127.74658203], [307.31...\n",
       "2    {'1.1': [[[331.99508667 127.74658203], [307.31...\n",
       "3    {'1.1': [[[nan nan], [nan nan], [nan nan], [na...\n",
       "4    {'1.1': [[[336.33197021 400.23355103], [319.35...\n",
       "Name: subject_to_tracks, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         (1.2)\n",
       "1    (1.1, 1.2)\n",
       "2    (1.1, 1.2)\n",
       "3         (1.1)\n",
       "4         (1.1)\n",
       "Name: subject_to_tracks, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"].apply(lambda x: x.keys()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_frame</th>\n",
       "      <th>stop_frame</th>\n",
       "      <th>tracked_subject</th>\n",
       "      <th>in_video_subjects</th>\n",
       "      <th>box_number</th>\n",
       "      <th>sleap_name</th>\n",
       "      <th>video_name</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>sleap_glob</th>\n",
       "      <th>sleap_path</th>\n",
       "      <th>all_sleap_data</th>\n",
       "      <th>body_parts</th>\n",
       "      <th>locations</th>\n",
       "      <th>track_names</th>\n",
       "      <th>subject_to_index</th>\n",
       "      <th>subject_to_tracks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32700</td>\n",
       "      <td>68257</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>1.1_1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>[/blue/npadillacoreano/ryoi360/projects/reward...</td>\n",
       "      <td>/blue/npadillacoreano/ryoi360/projects/reward_...</td>\n",
       "      <td>{'locations': [[[[244.3555603 ]\n",
       " [395.80090332...</td>\n",
       "      <td>[left_ear, right_ear, nose, tail_base, thorax,...</td>\n",
       "      <td>[[[[244.3555603], [395.80090332]], [[247.78367...</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>{'1.2': 0}</td>\n",
       "      <td>{'1.2': [[[244.3555603  395.80090332], [247.78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32300</td>\n",
       "      <td>[1.1, 1.2]</td>\n",
       "      <td>1.1_1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>[/blue/npadillacoreano/ryoi360/projects/reward...</td>\n",
       "      <td>/blue/npadillacoreano/ryoi360/projects/reward_...</td>\n",
       "      <td>{'locations': [[[[331.99508667 244.3555603 ]\n",
       " ...</td>\n",
       "      <td>[left_ear, right_ear, nose, tail_base, thorax,...</td>\n",
       "      <td>[[[[331.99508667 244.3555603 ], [127.74658203 ...</td>\n",
       "      <td>[1.1, 1.2]</td>\n",
       "      <td>{'1.1': 0, '1.2': 1}</td>\n",
       "      <td>{'1.1': [[[331.99508667 127.74658203], [307.31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32300</td>\n",
       "      <td>[1.1, 1.2]</td>\n",
       "      <td>1.1_1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>[/blue/npadillacoreano/ryoi360/projects/reward...</td>\n",
       "      <td>/blue/npadillacoreano/ryoi360/projects/reward_...</td>\n",
       "      <td>{'locations': [[[[331.99508667 244.3555603 ]\n",
       " ...</td>\n",
       "      <td>[left_ear, right_ear, nose, tail_base, thorax,...</td>\n",
       "      <td>[[[[331.99508667 244.3555603 ], [127.74658203 ...</td>\n",
       "      <td>[1.1, 1.2]</td>\n",
       "      <td>{'1.1': 0, '1.2': 1}</td>\n",
       "      <td>{'1.1': [[[331.99508667 127.74658203], [307.31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33000</td>\n",
       "      <td>68212</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>1.1_1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_112630_standard_comp_to_training_D1_s...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>[/blue/npadillacoreano/ryoi360/projects/reward...</td>\n",
       "      <td>/blue/npadillacoreano/ryoi360/projects/reward_...</td>\n",
       "      <td>{'locations': [[[[nan]\n",
       " [nan]], [[nan]\n",
       " [nan]]...</td>\n",
       "      <td>[left_ear, right_ear, nose, tail_base, thorax,...</td>\n",
       "      <td>[[[[nan], [nan]], [[nan], [nan]], [[nan], [nan...</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>{'1.1': 0}</td>\n",
       "      <td>{'1.1': [[[nan nan], [nan nan], [nan nan], [na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33400</td>\n",
       "      <td>68332</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>1.1_1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>20230613_105657_standard_comp_to_training_D2_s...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>[/blue/npadillacoreano/ryoi360/projects/reward...</td>\n",
       "      <td>/blue/npadillacoreano/ryoi360/projects/reward_...</td>\n",
       "      <td>{'locations': [[[[336.33197021]\n",
       " [400.23355103...</td>\n",
       "      <td>[left_ear, right_ear, nose, tail_base, thorax,...</td>\n",
       "      <td>[[[[336.33197021], [400.23355103]], [[319.3523...</td>\n",
       "      <td>[1.1]</td>\n",
       "      <td>{'1.1': 0}</td>\n",
       "      <td>{'1.1': [[[336.33197021 400.23355103], [319.35...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_frame  stop_frame tracked_subject in_video_subjects  box_number  \\\n",
       "0        32700       68257           [1.2]           1.1_1.2           1   \n",
       "1            1       32300      [1.1, 1.2]           1.1_1.2           1   \n",
       "2            1       32300      [1.1, 1.2]           1.1_1.2           1   \n",
       "3        33000       68212           [1.1]           1.1_1.2           2   \n",
       "4        33400       68332           [1.1]           1.1_1.4           1   \n",
       "\n",
       "                                          sleap_name  \\\n",
       "0  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "1  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "2  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "3  20230612_112630_standard_comp_to_training_D1_s...   \n",
       "4  20230613_105657_standard_comp_to_training_D2_s...   \n",
       "\n",
       "                                          video_name current_subject  \\\n",
       "0  20230612_112630_standard_comp_to_training_D1_s...             1.2   \n",
       "1  20230612_112630_standard_comp_to_training_D1_s...             1.1   \n",
       "2  20230612_112630_standard_comp_to_training_D1_s...             1.2   \n",
       "3  20230612_112630_standard_comp_to_training_D1_s...             1.1   \n",
       "4  20230613_105657_standard_comp_to_training_D2_s...             1.1   \n",
       "\n",
       "                                          sleap_glob  \\\n",
       "0  [/blue/npadillacoreano/ryoi360/projects/reward...   \n",
       "1  [/blue/npadillacoreano/ryoi360/projects/reward...   \n",
       "2  [/blue/npadillacoreano/ryoi360/projects/reward...   \n",
       "3  [/blue/npadillacoreano/ryoi360/projects/reward...   \n",
       "4  [/blue/npadillacoreano/ryoi360/projects/reward...   \n",
       "\n",
       "                                          sleap_path  \\\n",
       "0  /blue/npadillacoreano/ryoi360/projects/reward_...   \n",
       "1  /blue/npadillacoreano/ryoi360/projects/reward_...   \n",
       "2  /blue/npadillacoreano/ryoi360/projects/reward_...   \n",
       "3  /blue/npadillacoreano/ryoi360/projects/reward_...   \n",
       "4  /blue/npadillacoreano/ryoi360/projects/reward_...   \n",
       "\n",
       "                                      all_sleap_data  \\\n",
       "0  {'locations': [[[[244.3555603 ]\n",
       " [395.80090332...   \n",
       "1  {'locations': [[[[331.99508667 244.3555603 ]\n",
       " ...   \n",
       "2  {'locations': [[[[331.99508667 244.3555603 ]\n",
       " ...   \n",
       "3  {'locations': [[[[nan]\n",
       " [nan]], [[nan]\n",
       " [nan]]...   \n",
       "4  {'locations': [[[[336.33197021]\n",
       " [400.23355103...   \n",
       "\n",
       "                                          body_parts  \\\n",
       "0  [left_ear, right_ear, nose, tail_base, thorax,...   \n",
       "1  [left_ear, right_ear, nose, tail_base, thorax,...   \n",
       "2  [left_ear, right_ear, nose, tail_base, thorax,...   \n",
       "3  [left_ear, right_ear, nose, tail_base, thorax,...   \n",
       "4  [left_ear, right_ear, nose, tail_base, thorax,...   \n",
       "\n",
       "                                           locations track_names  \\\n",
       "0  [[[[244.3555603], [395.80090332]], [[247.78367...       [1.2]   \n",
       "1  [[[[331.99508667 244.3555603 ], [127.74658203 ...  [1.1, 1.2]   \n",
       "2  [[[[331.99508667 244.3555603 ], [127.74658203 ...  [1.1, 1.2]   \n",
       "3  [[[[nan], [nan]], [[nan], [nan]], [[nan], [nan...       [1.1]   \n",
       "4  [[[[336.33197021], [400.23355103]], [[319.3523...       [1.1]   \n",
       "\n",
       "       subject_to_index                                  subject_to_tracks  \n",
       "0            {'1.2': 0}  {'1.2': [[[244.3555603  395.80090332], [247.78...  \n",
       "1  {'1.1': 0, '1.2': 1}  {'1.1': [[[331.99508667 127.74658203], [307.31...  \n",
       "2  {'1.1': 0, '1.2': 1}  {'1.1': [[[331.99508667 127.74658203], [307.31...  \n",
       "3            {'1.1': 0}  {'1.1': [[[nan nan], [nan nan], [nan nan], [na...  \n",
       "4            {'1.1': 0}  {'1.1': [[[336.33197021 400.23355103], [319.35...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the coordinates of the corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/blue/npadillacoreano/ryoi360/projects/reward_comp/final_proc/id_corrected/20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1/20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.1.1_subj.id_corrected.h5'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"sleap_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each corner file is the in the same folder and has the same basename of the pose tracking file \n",
    "START_STOP_FRAME_DF[\"corner_path\"] = START_STOP_FRAME_DF[\"sleap_path\"].apply(lambda x: x.replace(\"id_corrected.h5\", \"corner.h5\").replace(\".fixed\", \"\").replace(\".round_1\", \"\").replace(\".1_subj\", \"\").replace(\".2_subj\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/blue/npadillacoreano/ryoi360/projects/reward_comp/final_proc/id_corrected/20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1/20230612_112630_standard_comp_to_training_D1_subj_1-2_and_1-1.1.corner.h5'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"corner_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the indexes of each corner location\n",
    "START_STOP_FRAME_DF[\"corner_parts\"] = START_STOP_FRAME_DF[\"corner_path\"].apply(lambda x: sleap.process_pose.get_node_names_from_sleap(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- '20230625_112913_standard_comp_to_both_rewarded_D4_subj_1-1_and_1-4.1'\n",
    "    - Look into why the corners have body parts instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20230625_112913_standard_comp_to_both_rewarded_D4_subj_1-1_and_1-4.1'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"video_name\"].iloc[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [box_top_left, box_top_right, reward_port, box...\n",
       "1     [box_top_left, box_top_right, reward_port, box...\n",
       "2     [box_top_left, box_top_right, reward_port, box...\n",
       "3     [box_bottom_left, box_top_right, reward_port, ...\n",
       "4     [box_bottom_left, box_top_right, reward_port, ...\n",
       "5     [box_bottom_left, box_top_right, reward_port, ...\n",
       "6     [box_bottom_left, box_top_right, reward_port, ...\n",
       "7     [box_bottom_left, box_top_right, reward_port, ...\n",
       "8     [box_bottom_left, box_top_right, reward_port, ...\n",
       "9     [box_bottom_left, box_top_right, reward_port, ...\n",
       "10    [box_bottom_left, box_top_right, reward_port, ...\n",
       "11    [box_bottom_left, box_top_right, reward_port, ...\n",
       "12    [box_bottom_left, box_top_right, reward_port, ...\n",
       "13    [box_bottom_left, box_top_right, reward_port, ...\n",
       "14    [box_bottom_left, box_top_right, reward_port, ...\n",
       "15    [box_bottom_left, box_top_right, reward_port, ...\n",
       "16    [box_bottom_left, box_top_right, reward_port, ...\n",
       "17    [box_bottom_left, box_top_left, box_top_right,...\n",
       "18    [box_bottom_left, box_top_left, box_top_right,...\n",
       "19    [reward_port, box_bottom_left, box_top_left, b...\n",
       "20    [reward_port, box_bottom_left, box_top_left, b...\n",
       "21    [reward_port, box_bottom_left, box_top_left, b...\n",
       "22    [reward_port, box_bottom_left, box_top_left, b...\n",
       "23    [box_top_left, reward_port, box_bottom_left, b...\n",
       "24    [box_top_left, reward_port, box_bottom_left, b...\n",
       "25    [left_ear, right_ear, nose, tail_base, thorax,...\n",
       "26    [left_ear, right_ear, nose, tail_base, thorax,...\n",
       "27    [box_bottom_left, reward_port, box_top_right, ...\n",
       "28    [box_bottom_left, reward_port, box_top_right, ...\n",
       "29    [box_bottom_left, reward_port, box_top_right, ...\n",
       "30    [box_bottom_left, reward_port, box_top_right, ...\n",
       "31    [box_bottom_left, reward_port, box_top_right, ...\n",
       "32    [box_bottom_left, reward_port, box_top_right, ...\n",
       "33    [box_bottom_left, reward_port, box_top_right, ...\n",
       "34    [box_bottom_left, reward_port, box_top_right, ...\n",
       "35    [box_bottom_left, reward_port, box_top_right, ...\n",
       "36    [box_bottom_left, reward_port, box_top_right, ...\n",
       "37    [box_bottom_left, reward_port, box_top_right, ...\n",
       "38    [box_bottom_left, reward_port, box_top_right, ...\n",
       "39    [box_bottom_left, reward_port, box_top_right, ...\n",
       "40    [box_bottom_left, reward_port, box_top_right, ...\n",
       "41    [box_bottom_left, reward_port, box_top_right, ...\n",
       "42    [box_bottom_left, reward_port, box_top_right, ...\n",
       "43    [box_bottom_left, reward_port, box_top_right, ...\n",
       "44    [box_bottom_left, reward_port, box_top_right, ...\n",
       "45    [box_bottom_left, reward_port, box_top_right, ...\n",
       "46    [box_bottom_left, reward_port, box_top_right, ...\n",
       "47    [box_bottom_left, reward_port, box_top_right, ...\n",
       "48    [box_bottom_left, reward_port, box_top_right, ...\n",
       "49    [box_bottom_left, reward_port, box_top_right, ...\n",
       "50    [box_bottom_left, reward_port, box_top_right, ...\n",
       "51    [box_bottom_left, reward_port, box_top_right, ...\n",
       "52    [box_bottom_left, reward_port, box_top_right, ...\n",
       "Name: corner_parts, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"corner_parts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['box_top_left',\n",
       " 'box_top_right',\n",
       " 'reward_port',\n",
       " 'box_bottom_left',\n",
       " 'box_bottom_right']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"corner_parts\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Remove this once corner files are fixed\n",
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF[START_STOP_FRAME_DF[\"corner_parts\"].apply(lambda x: \"reward_port\" in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/24060335/ipykernel_2719052/277501212.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  START_STOP_FRAME_DF[\"corner_to_coordinate\"] = START_STOP_FRAME_DF[\"corner_path\"].apply(lambda x: sleap.process_pose.get_sleap_tracks_from_h5(x))\n"
     ]
    }
   ],
   "source": [
    "# Getting the coordinates of all the corners\n",
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"] = START_STOP_FRAME_DF[\"corner_path\"].apply(lambda x: sleap.process_pose.get_sleap_tracks_from_h5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/24060335/ipykernel_2719052/129892389.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  START_STOP_FRAME_DF[\"corner_to_coordinate\"] = START_STOP_FRAME_DF.apply(lambda x: {part: x[\"corner_to_coordinate\"][:,index,:,:] for index, part in enumerate(x[\"corner_parts\"])}, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Parsing out each corner and creating a dictionary of name to coordinates\n",
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"] = START_STOP_FRAME_DF.apply(lambda x: {part: x[\"corner_to_coordinate\"][:,index,:,:] for index, part in enumerate(x[\"corner_parts\"])}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Figure out why some corners are nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'box_top_left': [[[nan], [nan]], [[nan], [nan...\n",
       "1     {'box_top_left': [[[nan], [nan]], [[nan], [nan...\n",
       "2     {'box_top_left': [[[nan], [nan]], [[nan], [nan...\n",
       "3     {'box_bottom_left': [[[234.69934175], [389.572...\n",
       "4     {'box_bottom_left': [[[219.49634883], [382.936...\n",
       "5     {'box_bottom_left': [[[219.49634883], [382.936...\n",
       "6     {'box_bottom_left': [[[219.49634883], [382.936...\n",
       "7     {'box_bottom_left': [[[234.47302231], [387.438...\n",
       "8     {'box_bottom_left': [[[218.76658435], [382.320...\n",
       "9     {'box_bottom_left': [[[218.76658435], [382.320...\n",
       "10    {'box_bottom_left': [[[218.76658435], [382.320...\n",
       "11    {'box_bottom_left': [[[234.49380639], [387.021...\n",
       "12    {'box_bottom_left': [[[219.48526849], [382.698...\n",
       "13    {'box_bottom_left': [[[220.39193729], [383.559...\n",
       "14    {'box_bottom_left': [[[220.39193729], [383.559...\n",
       "15    {'box_bottom_left': [[[220.39193729], [383.559...\n",
       "16    {'box_bottom_left': [[[232.92760122], [389.100...\n",
       "17    {'box_bottom_left': [[[215.66257348          n...\n",
       "18    {'box_bottom_left': [[[215.66257348          n...\n",
       "19    {'reward_port': [[[327.01342342], [402.8180895...\n",
       "20    {'reward_port': [[[327.01342342], [402.8180895...\n",
       "21    {'reward_port': [[[327.57937164], [403.2443790...\n",
       "22    {'reward_port': [[[327.57937164], [403.2443790...\n",
       "23    {'box_top_left': [[[215.91099101          nan]...\n",
       "24    {'box_top_left': [[[215.91099101          nan]...\n",
       "27    {'box_bottom_left': [[[218.06618478          n...\n",
       "28    {'box_bottom_left': [[[218.06618478          n...\n",
       "29    {'box_bottom_left': [[[218.06618478          n...\n",
       "30    {'box_bottom_left': [[[218.06618478          n...\n",
       "31    {'box_bottom_left': [[[233.2927994         nan...\n",
       "32    {'box_bottom_left': [[[233.2927994         nan...\n",
       "33    {'box_bottom_left': [[[234.75452291          n...\n",
       "34    {'box_bottom_left': [[[234.75452291          n...\n",
       "35    {'box_bottom_left': [[[233.26184605], [386.388...\n",
       "36    {'box_bottom_left': [[[233.26184605], [386.388...\n",
       "37    {'box_bottom_left': [[[219.73308791          n...\n",
       "38    {'box_bottom_left': [[[219.73308791          n...\n",
       "39    {'box_bottom_left': [[[219.73308791          n...\n",
       "40    {'box_bottom_left': [[[219.73308791          n...\n",
       "41    {'box_bottom_left': [[[232.63349486], [388.585...\n",
       "42    {'box_bottom_left': [[[232.63349486], [388.585...\n",
       "43    {'box_bottom_left': [[[232.63349486], [388.585...\n",
       "44    {'box_bottom_left': [[[232.63349486], [388.585...\n",
       "45    {'box_bottom_left': [[[216.16270965], [386.158...\n",
       "46    {'box_bottom_left': [[[216.16270965], [386.158...\n",
       "47    {'box_bottom_left': [[[216.16270965], [386.158...\n",
       "48    {'box_bottom_left': [[[216.16270965], [386.158...\n",
       "49    {'box_bottom_left': [[[230.39644068], [395.236...\n",
       "50    {'box_bottom_left': [[[230.39644068], [395.236...\n",
       "51    {'box_bottom_left': [[[230.39644068], [395.236...\n",
       "52    {'box_bottom_left': [[[230.39644068], [395.236...\n",
       "Name: corner_to_coordinate, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/24060335/ipykernel_2719052/2482341573.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  START_STOP_FRAME_DF[\"corner_to_coordinate\"] = START_STOP_FRAME_DF.apply(lambda x: {k: v[~np.isnan(v)][:2] for k, v in x[\"corner_to_coordinate\"].items()}, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Filtering out all the Nans because there's only one labeled frame\n",
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"] = START_STOP_FRAME_DF.apply(lambda x: {k: v[~np.isnan(v)][:2] for k, v in x[\"corner_to_coordinate\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'box_top_left': [215.09666220678088, 113.9234...\n",
       "1     {'box_top_left': [215.09666220678088, 113.9234...\n",
       "2     {'box_top_left': [215.09666220678088, 113.9234...\n",
       "3     {'box_bottom_left': [234.69934174733294, 389.5...\n",
       "4     {'box_bottom_left': [219.49634882813532, 382.9...\n",
       "5     {'box_bottom_left': [219.49634882813532, 382.9...\n",
       "6     {'box_bottom_left': [219.49634882813532, 382.9...\n",
       "7     {'box_bottom_left': [234.47302230577947, 387.4...\n",
       "8     {'box_bottom_left': [218.76658435012303, 382.3...\n",
       "9     {'box_bottom_left': [218.76658435012303, 382.3...\n",
       "10    {'box_bottom_left': [218.76658435012303, 382.3...\n",
       "11    {'box_bottom_left': [234.49380639157778, 387.0...\n",
       "12    {'box_bottom_left': [219.48526849018168, 382.6...\n",
       "13    {'box_bottom_left': [220.39193729003364, 383.5...\n",
       "14    {'box_bottom_left': [220.39193729003364, 383.5...\n",
       "15    {'box_bottom_left': [220.39193729003364, 383.5...\n",
       "16    {'box_bottom_left': [232.9276012199772, 389.10...\n",
       "17    {'box_bottom_left': [215.66257348338468, 385.5...\n",
       "18    {'box_bottom_left': [215.66257348338468, 385.5...\n",
       "19    {'reward_port': [327.01342341696227, 402.81808...\n",
       "20    {'reward_port': [327.01342341696227, 402.81808...\n",
       "21    {'reward_port': [327.57937164167924, 403.24437...\n",
       "22    {'reward_port': [327.57937164167924, 403.24437...\n",
       "23    {'box_top_left': [215.91099101388411, 388.6338...\n",
       "24    {'box_top_left': [215.91099101388411, 388.6338...\n",
       "27    {'box_bottom_left': [218.06618477558823, 385.0...\n",
       "28    {'box_bottom_left': [218.06618477558823, 385.0...\n",
       "29    {'box_bottom_left': [218.06618477558823, 385.0...\n",
       "30    {'box_bottom_left': [218.06618477558823, 385.0...\n",
       "31    {'box_bottom_left': [233.29279939968015, 389.0...\n",
       "32    {'box_bottom_left': [233.29279939968015, 389.0...\n",
       "33    {'box_bottom_left': [234.75452291039738, 390.3...\n",
       "34    {'box_bottom_left': [234.75452291039738, 390.3...\n",
       "35    {'box_bottom_left': [233.26184605380837, 386.3...\n",
       "36    {'box_bottom_left': [233.26184605380837, 386.3...\n",
       "37    {'box_bottom_left': [219.73308790589675, 390.2...\n",
       "38    {'box_bottom_left': [219.73308790589675, 390.2...\n",
       "39    {'box_bottom_left': [219.73308790589675, 390.2...\n",
       "40    {'box_bottom_left': [219.73308790589675, 390.2...\n",
       "41    {'box_bottom_left': [232.6334948649877, 388.58...\n",
       "42    {'box_bottom_left': [232.6334948649877, 388.58...\n",
       "43    {'box_bottom_left': [232.6334948649877, 388.58...\n",
       "44    {'box_bottom_left': [232.6334948649877, 388.58...\n",
       "45    {'box_bottom_left': [216.16270964603552, 386.1...\n",
       "46    {'box_bottom_left': [216.16270964603552, 386.1...\n",
       "47    {'box_bottom_left': [216.16270964603552, 386.1...\n",
       "48    {'box_bottom_left': [216.16270964603552, 386.1...\n",
       "49    {'box_bottom_left': [230.39644068293484, 395.2...\n",
       "50    {'box_bottom_left': [230.39644068293484, 395.2...\n",
       "51    {'box_bottom_left': [230.39644068293484, 395.2...\n",
       "52    {'box_bottom_left': [230.39644068293484, 395.2...\n",
       "Name: corner_to_coordinate, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the distances between corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the average width and height so that we can convert pixels to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/24060335/ipykernel_2719052/2243602241.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  START_STOP_FRAME_DF[\"bottom_width\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_right\"][0] - x[\"box_bottom_left\"][0])\n",
      "/scratch/local/24060335/ipykernel_2719052/2243602241.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  START_STOP_FRAME_DF[\"top_width\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_top_right\"][0] - x[\"box_top_left\"][0])\n"
     ]
    }
   ],
   "source": [
    "# Using the x-coordinates for the width\n",
    "START_STOP_FRAME_DF[\"bottom_width\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_right\"][0] - x[\"box_bottom_left\"][0])\n",
    "START_STOP_FRAME_DF[\"top_width\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_top_right\"][0] - x[\"box_top_left\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/24060335/ipykernel_2719052/1007448330.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  START_STOP_FRAME_DF[\"right_height\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_right\"][1] - x[\"box_top_right\"][1])\n",
      "/scratch/local/24060335/ipykernel_2719052/1007448330.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  START_STOP_FRAME_DF[\"left_height\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_left\"][1] - x[\"box_top_left\"][1])\n"
     ]
    }
   ],
   "source": [
    "# Using the y-coordinates for the height\n",
    "START_STOP_FRAME_DF[\"right_height\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_right\"][1] - x[\"box_top_right\"][1])\n",
    "START_STOP_FRAME_DF[\"left_height\"] = START_STOP_FRAME_DF[\"corner_to_coordinate\"].apply(lambda x: x[\"box_bottom_left\"][1] - x[\"box_top_left\"][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/24060335/ipykernel_2719052/568356970.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  START_STOP_FRAME_DF[\"average_height\"] = START_STOP_FRAME_DF.apply(lambda row: (row[\"right_height\"] + row[\"left_height\"])/2, axis=1)\n",
      "/scratch/local/24060335/ipykernel_2719052/568356970.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  START_STOP_FRAME_DF[\"average_width\"] = START_STOP_FRAME_DF.apply(lambda row: (row[\"bottom_width\"] + row[\"top_width\"])/2, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# averaging the width and height by adding both sides and then getting the mean\n",
    "START_STOP_FRAME_DF[\"average_height\"] = START_STOP_FRAME_DF.apply(lambda row: (row[\"right_height\"] + row[\"left_height\"])/2, axis=1)\n",
    "START_STOP_FRAME_DF[\"average_width\"] = START_STOP_FRAME_DF.apply(lambda row: (row[\"bottom_width\"] + row[\"top_width\"])/2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Figure out why average height is so low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     266.715544\n",
       "1     266.715544\n",
       "2     266.715544\n",
       "3     262.551593\n",
       "4     263.215010\n",
       "5     263.215010\n",
       "6     263.215010\n",
       "7     263.220692\n",
       "8     260.889234\n",
       "9     260.889234\n",
       "10    260.889234\n",
       "11    263.121313\n",
       "12    262.412119\n",
       "13    264.041942\n",
       "14    264.041942\n",
       "15    264.041942\n",
       "16    261.262437\n",
       "17    262.119650\n",
       "18    262.119650\n",
       "19    266.281781\n",
       "20    266.281781\n",
       "21    264.219046\n",
       "22    264.219046\n",
       "23      3.080119\n",
       "24      3.080119\n",
       "27    259.815529\n",
       "28    259.815529\n",
       "29    259.815529\n",
       "30    259.815529\n",
       "31    262.862896\n",
       "32    262.862896\n",
       "33    257.898587\n",
       "34    257.898587\n",
       "35    259.055487\n",
       "36    259.055487\n",
       "37    262.008238\n",
       "38    262.008238\n",
       "39    262.008238\n",
       "40    262.008238\n",
       "41    260.866315\n",
       "42    260.866315\n",
       "43    260.866315\n",
       "44    260.866315\n",
       "45    260.449185\n",
       "46    260.449185\n",
       "47    260.449185\n",
       "48    260.449185\n",
       "49    265.973648\n",
       "50    265.973648\n",
       "51    265.973648\n",
       "52    265.973648\n",
       "Name: average_height, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STOP_FRAME_DF[\"average_height\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getthing the pixel to cm ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"width_ratio\"] = MED_PC_WIDTH / START_STOP_FRAME_DF[\"average_width\"]\n",
    "START_STOP_FRAME_DF[\"height_ratio\"] = MED_PC_HEIGHT / START_STOP_FRAME_DF[\"average_height\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"height_ratio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"width_ratio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Pixels to cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"].iloc[0][\"1.1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"in_video_subjects\"] = START_STOP_FRAME_DF[\"in_video_subjects\"].apply(lambda x: x.split(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"] = START_STOP_FRAME_DF.apply(lambda x: {k: v for k, v in x[\"subject_to_tracks\"].items() if k in x[\"in_video_subjects\"]}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the X-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"subject_to_tracks\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"rescaled_locations\"] = START_STOP_FRAME_DF.apply(lambda x: {key: sleap.process_pose.fill_missing(sleap.process_pose.rescale_dimension_in_array(value, dimension=0, ratio=x[\"width_ratio\"])) for key, value in x[\"subject_to_tracks\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the Y-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"rescaled_locations\"] = START_STOP_FRAME_DF.apply(lambda x: {key: sleap.process_pose.rescale_dimension_in_array(value, dimension=1, ratio=x[\"height_ratio\"]) for key, value in x[\"rescaled_locations\"].items()}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"corner_to_coordinate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize dictionary column\n",
    "normalized = pd.json_normalize(START_STOP_FRAME_DF[\"corner_to_coordinate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Drop the original column and concat the normalized DataFrame\n",
    "START_STOP_FRAME_DF = pd.concat([START_STOP_FRAME_DF.drop([\"corner_to_coordinate\"], axis=1), normalized], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF = START_STOP_FRAME_DF.dropna(subset=[\"reward_port\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corner in START_STOP_FRAME_DF[\"corner_parts\"].iloc[0]:\n",
    "    START_STOP_FRAME_DF[corner] = START_STOP_FRAME_DF.apply(lambda x: [x[corner][0]*x[\"width_ratio\"], x[corner][1]*x[\"height_ratio\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking over the tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"sleap_path\"].iloc[FILE_INDEX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"rescaled_locations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(LFP_AND_SLEAP_DF[\"sleap_path\"].iloc[FILE_INDEX], \"r\") as f:\n",
    "    dset_names = list(f.keys())\n",
    "    current_subject = LFP_AND_SLEAP_DF[\"subject\"].iloc[FILE_INDEX]\n",
    "    locations = LFP_AND_SLEAP_DF[\"rescaled_locations\"].iloc[FILE_INDEX][current_subject]\n",
    "    node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "    \n",
    "print(\"===HDF5 datasets===\")\n",
    "print(dset_names)\n",
    "print()\n",
    "\n",
    "print(\"===locations data shape===\")\n",
    "print(locations.shape)\n",
    "print()\n",
    "\n",
    "print(\"===nodes===\")\n",
    "for i, name in enumerate(node_names):\n",
    "    print(f\"{i}: {name}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thorax_loc = locations[:, THORAX_INDEX, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(thorax_loc[:,0],label='X-coordinates')\n",
    "# Converting to negative so that we can see both x and y track\n",
    "plt.plot(-1*thorax_loc[:,1], label='Y-coordinates')\n",
    "\n",
    "plt.legend(loc=\"center right\")\n",
    "plt.title('Thorax locations')\n",
    "plt.xlabel(\"Time in frames\")\n",
    "plt.ylabel(\"Coordinate Position\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(thorax_loc[:,0],thorax_loc[:,1])\n",
    "\n",
    "\n",
    "plt.title('Thorax tracks')\n",
    "plt.xlabel(\"X-Coordinates\")\n",
    "plt.ylabel(\"Y-Coordinates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an individual column for each pose tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF = LFP_AND_SLEAP_DF.dropna(subset=\"current_subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFP_AND_SLEAP_DF[\"agent\"] = LFP_AND_SLEAP_DF.apply(lambda x: list(set(x[\"all_subjects\"]) - set(x[\"subject\"]))[0], axis=1)\n",
    "\n",
    "LFP_AND_SLEAP_DF[\"agent\"] = LFP_AND_SLEAP_DF.apply(lambda x: list((set(x[\"in_video_subjects\"]) - set([x[\"current_subject\"]])))[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"subject_locations\"] = LFP_AND_SLEAP_DF.apply(lambda x: x[\"rescaled_locations\"][x[\"subject\"]] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"agent_locations\"] = LFP_AND_SLEAP_DF.apply(lambda x: x[\"rescaled_locations\"].get(x[\"agent\"], np.nan) , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF = LFP_AND_SLEAP_DF.drop([\"sleap_glob\", \"subject_to_index\", \"subject_to_tracks\", \"corner_parts\", \"corner_to_coordinate\", \"bottom_width\", \"top_width\", \"right_height\", \"left_height\", \"average_height\", \"average_width\", \"width_ratio\", \"height_ratio\", 'locations', 'current_subject', 'track_names', 'sleap_path', 'corner_path', 'all_sleap_data', 'rescaled_locations'], errors=\"ignore\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"subject_locations\"].apply(lambda x: x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"body_parts\"].apply(lambda x: x.index(\"thorax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"subject_thorax_velocity\"] = LFP_AND_SLEAP_DF.apply(lambda x: compute_velocity(x[\"subject_locations\"][:,x[\"body_parts\"].index(\"thorax\"),:], window_size=FRAME_RATE*3) * FRAME_RATE, axis=1)\n",
    "LFP_AND_SLEAP_DF[\"subject_thorax_velocity\"] = LFP_AND_SLEAP_DF[\"subject_thorax_velocity\"].apply(lambda x: x.astype(np.float16) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"agent_thorax_velocity\"] = LFP_AND_SLEAP_DF.apply(lambda x: compute_velocity(x[\"agent_locations\"][:,x[\"body_parts\"].index(\"thorax\"),:], window_size=FRAME_RATE*3) * FRAME_RATE if x[\"agent_locations\"] is not np.nan else np.nan, axis=1)\n",
    "LFP_AND_SLEAP_DF[\"agent_thorax_velocity\"] = LFP_AND_SLEAP_DF[\"agent_thorax_velocity\"].apply(lambda x: x.astype(np.float16) if x is not np.nan else np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"subject_thorax_velocity\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate distance to reward port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"subject_thorax_to_reward_port\"] = LFP_AND_SLEAP_DF.apply(lambda x: np.linalg.norm(x[\"subject_locations\"][:,x[\"body_parts\"].index(\"thorax\"),:] - x[\"reward_port\"], axis=1),  axis=1)\n",
    "LFP_AND_SLEAP_DF[\"subject_thorax_to_reward_port\"] = LFP_AND_SLEAP_DF[\"subject_thorax_to_reward_port\"].apply(lambda x: x.astype(np.float16) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"agent_thorax_to_reward_port\"] = LFP_AND_SLEAP_DF.apply(lambda x: np.linalg.norm(x[\"agent_locations\"][:,x[\"body_parts\"].index(\"thorax\"),:] - x[\"reward_port\"], axis=1) if x[\"agent_locations\"] is not np.nan else np.nan,  axis=1)\n",
    "LFP_AND_SLEAP_DF[\"agent_thorax_to_reward_port\"] = LFP_AND_SLEAP_DF[\"agent_thorax_to_reward_port\"].apply(lambda x: x.astype(np.float16) if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.to_pickle(os.path.join(OUTPUT_DIR, FULL_LFP_TRACES_PKL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Velocity timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_TRIAL_AND_SLEAP[\"full-recording_subject_thorax_velocity\"] = MERGED_TRIAL_AND_SLEAP[\"full-recording_subject_thorax_location_all-frames\"].apply(lambda x: compute_velocity(x, window_size=FRAME_RATE*3) * FRAME_RATE)\n",
    "\n",
    "MERGED_TRIAL_AND_SLEAP[\"full-recording_agent_thorax_velocity\"] = MERGED_TRIAL_AND_SLEAP[\"full-recording_agent_thorax_location_all-frames\"].apply(lambda x: compute_velocity(x, window_size=FRAME_RATE*3) * FRAME_RATE if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_TRIAL_AND_SLEAP[\"full-recording_subject_thorax_velocity\"] = MERGED_TRIAL_AND_SLEAP[\"full-recording_subject_thorax_location_all-frames\"].apply(lambda x: compute_velocity(x, window_size=FRAME_RATE*3) * FRAME_RATE)\n",
    "\n",
    "MERGED_TRIAL_AND_SLEAP[\"full-recording_agent_thorax_velocity\"] = MERGED_TRIAL_AND_SLEAP[\"full-recording_agent_thorax_location_all-frames\"].apply(lambda x: compute_velocity(x, window_size=FRAME_RATE*3) * FRAME_RATE if x is not np.nan else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding the start/stop frame information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_locations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting relevant metadata for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the rows that have two subjects\n",
    "subject_locations[\"tracked_subject\"] = subject_locations[\"tracked_subject\"].apply(lambda x: str(x).split(\"_\"))\n",
    "subject_locations = subject_locations[subject_locations[\"tracked_subject\"].apply(lambda x: len(x) == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sleap filename from file path\n",
    "subject_locations[\"sleap_filename\"] = subject_locations[\"file_path\"].apply(lambda x: os.path.basename(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the sleap fileroot from the sleap filename\n",
    "subject_locations[\"sleap_fileroot\"] = subject_locations[\"sleap_filename\"].apply(lambda x: \".\".join(x.split(\".\")[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the start and stop frame columns into a tuple\n",
    "subject_locations[\"start_stop_frame\"] = subject_locations.apply(lambda x: (int(x[\"start_frame\"]), int(x[\"stop_frame\"])), axis=1)\n",
    "subject_locations = subject_locations.drop(columns=[\"start_frame\", \"stop_frame\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merging the dataframes based on shared SLEAP file basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF = pd.merge(left=LFP_AND_SLEAP_DF, right=subject_locations, left_on=\"video_name\", right_on=\"sleap_fileroot\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converting the start/stop frames into timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"start_stop_timestamps\"] = LFP_AND_SLEAP_DF.apply(lambda x: (x[\"video_timestamps\"][x[\"start_stop_frame\"][0]], x[\"video_timestamps\"][x[\"start_stop_frame\"][1]]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going from frame information to ephys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering for parts of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trace_col in [col for col in LFP_AND_SLEAP_DF.columns if \"lfp_trace\" in col]:\n",
    "    print(trace_col)\n",
    "    brain_region = trace_col.split(\"_\")[0]\n",
    "    LFP_AND_SLEAP_DF[\"filtered_{}_trace\".format(brain_region)] = LFP_AND_SLEAP_DF.apply(lambda x: utilities.helper.filter_by_timestamp_range(x[\"start_stop_timestamps\"][0], x[\"start_stop_timestamps\"][1], x[\"lfp_timestamps\"], x[trace_col])[1], axis=1)\n",
    "LFP_AND_SLEAP_DF[\"filtered_lfp_timestamps\"] = LFP_AND_SLEAP_DF.apply(lambda x: utilities.helper.filter_by_timestamp_range(x[\"start_stop_timestamps\"][0], x[\"start_stop_timestamps\"][1], x[\"lfp_timestamps\"], x[\"lfp_timestamps\"])[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF = LFP_AND_SLEAP_DF.drop(columns=[col for col in LFP_AND_SLEAP_DF.columns if \"lfp_trace\" in col], errors=\"ignore\")\n",
    "LFP_AND_SLEAP_DF = LFP_AND_SLEAP_DF.drop(columns=[\"lfp_timestamps\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"video_timestamps\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"video_timestamps\"].apply(lambda x: x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"subject_locations\"].apply(lambda x: x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"recording\"].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"filtered_subject_locations\"] = LFP_AND_SLEAP_DF.apply(lambda x: utilities.helper.filter_by_timestamp_range(x[\"start_stop_timestamps\"][0], x[\"start_stop_timestamps\"][1], x[\"video_timestamps\"], x[\"subject_locations\"])[1], axis=1)\n",
    "LFP_AND_SLEAP_DF[\"filtered_agent_locations\"] = LFP_AND_SLEAP_DF.apply(lambda x: utilities.helper.filter_by_timestamp_range(x[\"start_stop_timestamps\"][0], x[\"start_stop_timestamps\"][1], x[\"video_timestamps\"], x[\"agent_locations\"])[1], axis=1)\n",
    "LFP_AND_SLEAP_DF[\"filtered_video_timestamps\"] = LFP_AND_SLEAP_DF.apply(lambda x: utilities.helper.filter_by_timestamp_range(x[\"start_stop_timestamps\"][0], x[\"start_stop_timestamps\"][1], x[\"video_timestamps\"], x[\"video_timestamps\"])[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF = LFP_AND_SLEAP_DF.drop(columns=[\"video_timestamps\", \"subject_locations\", \"agent_locations\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting column names for easier reading\n",
    "sorted_columns = sorted(LFP_AND_SLEAP_DF.columns, key=lambda x: x.split(\"_\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF = LFP_AND_SLEAP_DF[sorted_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.to_pickle(os.path.join(OUTPUT_DIR, FULL_LFP_TRACES_PKL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_timestamp_indices(timestamps, other_timestamps, start_index=0, stop_index=1):\n",
    "    \"\"\"\n",
    "    Converts the start and stop indices of one data stream to timestamps, and then finds the nearest start and stop \n",
    "    timestamps in another data stream.\n",
    "\n",
    "    Parameters:\n",
    "    - timestamps (list[int or float]): The list of timestamps in the first data stream.\n",
    "    - other_timestamps (list[int or float]): The list of timestamps in the other data stream.\n",
    "    - start_index (int, optional): The start index in the first data stream. Defaults to 0.\n",
    "    - stop_index (int, optional): The stop index in the first data stream. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: The indices of the nearest start and stop timestamps in the other data stream.\n",
    "    \"\"\"\n",
    "    # Convert start and stop indices to timestamps\n",
    "    start_timestamp = timestamps[start_index]\n",
    "    stop_timestamp = timestamps[stop_index]\n",
    "\n",
    "    # Find nearest start and stop timestamps in other data stream\n",
    "    nearest_start_index = utilities.helper.find_nearest_index(other_timestamps, start_timestamp)\n",
    "    nearest_stop_index = utilities.helper.find_nearest_index(other_timestamps, stop_timestamp) \n",
    "\n",
    "    return nearest_start_index, nearest_stop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raise ValueError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Getting the names of each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"video_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glob.glob(SLEAP_DIR+ \"/*/*id_corrected*.h5\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SLEAP_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LFP_AND_SLEAP_DF[\"video_path\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"video_name\"].apply(lambda x: os.path.join(SLEAP_DIR, \"*\", x + \"*.h5\"))\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"sleap_glob\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"video_name\"].apply(lambda x: glob.glob(os.path.join(SLEAP_DIR, \"*\", x + \"*id_corrected*.h5\")))\n",
    "# VIDEO_TO_FRAME_AND_SUBJECT_DF[\"sleap_glob\"] = VIDEO_TO_FRAME_AND_SUBJECT_DF[\"video_name\"].apply(lambda x: os.path.join(SLEAP_DIR, \"*\", x + \"*2_subj*.h5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = VIDEO_TO_FRAME_AND_SUBJECT_DF[VIDEO_TO_FRAME_AND_SUBJECT_DF['sleap_glob'].apply(lambda x: len(x) >= 1)]\n",
    "VIDEO_TO_FRAME_AND_SUBJECT_DF = VIDEO_TO_FRAME_AND_SUBJECT_DF.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"sleap_glob\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD merging code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting together LFP and video start/stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"video_name\"].unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"video_name\"].unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VIDEO_TO_FRAME_AND_SUBJECT_DF[\"current_subject\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "START_STOP_FRAME_DF[\"current_subject\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF = pd.merge(VIDEO_TO_FRAME_AND_SUBJECT_DF, START_STOP_FRAME_DF, on=[\"video_name\", \"current_subject\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFP_AND_SLEAP_DF[\"video_timestamps\"].apply(lambda x: x.shape).head()"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "spike_interface_0_99_0",
   "language": "python",
   "name": "spike_interface_0_99_0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
