{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Notebook 1: Extract Z-scored LFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This Jupyter notebook focuses on extracting local field potential (LFP) traces from Spikegadgets `.rec` files, specifically for neuroscience research related to social competition trials. The notebook includes procedures for preprocessing and synchronizing raw electrophysiology data with corresponding video data and computes various metrics, including Z-scored LFPs.\n",
    "\n",
    "### Inputs & Data Sources\n",
    "- **Electrophysiology and LFP Parameters**: Constants like `EPHYS_SAMPLING_RATE`, `LFP_SAMPLING_RATE`, `TRIAL_DURATION`, etc., define basic parameters for LFP data processing.\n",
    "- **Recording Information**: Stream IDs (`ECU_STREAM_ID`, `TRODES_STREAM_ID`), recording extension (`RECORDING_EXTENSION`), and paths to recording directories (`ALL_SESSION_DIR`).\n",
    "- **DataFrames for Mapping and Timestamps**: `CHANNEL_MAPPING_DF` for channel mapping, and `TONE_TIMESTAMP_DF` for tone timestamps, loaded from external sources.\n",
    "- **Constants for DataFrame Columns**: Names for various columns in the DataFrame, defined in an all-caps snake case format, such as `EPHYS_INDEX_COL`, `LFP_INDEX_COL`, etc.\n",
    "\n",
    "### Output & Utility\n",
    "- **Processed Data**: The notebook outputs processed data, particularly the Z-scored LFP traces, which are critical for further analysis in neuroscience research.\n",
    "- **Data Files**: Outputs are saved in various formats (`CSV`, `Pickle`) in a specified output directory (`OUTPUT_DIR`).\n",
    "- **Visualization**: While not explicitly mentioned, the notebook has the potential for data visualization (plots) based on processed LFP data.\n",
    "\n",
    "### Processing Workflow\n",
    "1. **LFP Extraction and Preprocessing**: \n",
    "    - Iterates through recording sessions to process `.rec` files.\n",
    "    - Applies a series of preprocessing steps like bandpass filtering, notch filtering, resampling, and Z-scoring on the LFP data.\n",
    "    - Exception handling for cases where the recording doesn't contain specified stream IDs.\n",
    "\n",
    "2. **DataFrame Manipulation and Merging**:\n",
    "    - Filtering `TONE_TIMESTAMP_DF` for trials with obtained LFP.\n",
    "    - Addition of trial numbers and merging with `CHANNEL_MAPPING_DF`.\n",
    "    - Dropping unnecessary columns and restructuring for analysis.\n",
    "\n",
    "3. **LFP Trace Extraction for Each Trial and Brain Region**: \n",
    "    - Linking LFP calculations with trials.\n",
    "    - Creating new rows for each brain region, extracting baseline, trial, and combined LFP traces.\n",
    "    - Results in a comprehensive DataFrame that combines trial information with corresponding LFP traces.\n",
    "\n",
    "4. **Data Storage**:\n",
    "    - Saving processed DataFrame in both `CSV` and `Pickle` formats for easy access and future use.\n",
    "\n",
    "### Usage Notes\n",
    "- The notebook is project-specific and tailored for a particular dataset structure, requiring modifications for different data formats.\n",
    "- Users should ensure file paths and directory names match their project's structure and adjust constants and parameters as needed for their specific analysis requirements.\n",
    "- The notebook forms a part of a larger research framework, thus necessitating compatibility checks with other components of the project.\n",
    "\n",
    "### Dependencies\n",
    "- Python Libraries: `sys`, `os`, `glob`, `numpy`, `pandas`, `spikeinterface`\n",
    "- External Data: Channel mapping and tone timestamp files, along with Spikegadgets `.rec` files.\n",
    "\n",
    "### Customization and Scalability\n",
    "- The notebook's modular design allows for easy adaptation to different datasets or extensions to include additional processing steps.\n",
    "- Functions and processing steps are clearly demarcated, facilitating straightforward updates or enhancements.\n",
    "\n",
    "### Conclusion\n",
    "This notebook is a vital tool in the preprocessing and analysis of LFP data from Spikegadgets recordings, integral to neuroscience research focused on social competition trials. It offers a structured approach to handle, process, and store electrophysiological data, ensuring reproducibility and efficiency in research workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "git_repo = git.Repo(\".\", search_parent_directories=True)\n",
    "git_root = git_repo.git.rev_parse(\"--show-toplevel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/blue/npadillacoreano/ryoi360/projects/reward_competition_extention'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(git_root, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPHYS_SAMPLING_RATE = 20000\n",
    "LFP_SAMPLING_RATE = 1000\n",
    "TRIAL_DURATION = 10\n",
    "FRAME_RATE = 22\n",
    "ECU_STREAM_ID = \"ECU\"\n",
    "TRODES_STREAM_ID = \"trodes\"\n",
    "LFP_FREQ_MIN = 0.5\n",
    "LFP_FREQ_MAX = 300\n",
    "ELECTRIC_NOISE_FREQ = 60\n",
    "RECORDING_EXTENTION = \"*.rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPHYS_INDEX_COL = \"time_stamp_index\"\n",
    "LFP_INDEX_COL = \"lfp_index\"\n",
    "EPHYS_TIMESTAMP_COL = \"time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RECORDING_FILE_COL = \"recording_file\"\n",
    "RECORDING_DIR_COL = \"recording_dir\"\n",
    "BASELINE_LFP_INDEX_RANGE_COL = \"baseline_lfp_index_range\"\n",
    "TRIAL_LFP_INDEX_RANGE_COL = \"trial_lfp_index_range\"\n",
    "BASELINE_EPHYS_INDEX_RANGE_COL = \"baseline_ephys_index_range\"\n",
    "TRIAL_EPHYS_INDEX_RANGE_COL = \"trial_ephys_index_range\"\n",
    "BASELINE_VIDEOFRAME_RANGE_COL = \"baseline_videoframe_range\"\n",
    "TRIAL_VIDEOFRAME_RANGE_COL = \"trial_videoframe_range\"\n",
    "CURRENT_SUBJECT_COL = \"current_subject\"\n",
    "ALL_CH_LFP_COL = \"all_ch_lfp\"\n",
    "SUBJECT_COL = \"Subject\"\n",
    "TRIAL_NUMBER_COL = \"trial_number\"\n",
    "SPIKE_INTERFACE_COL = \"spike_interface\"\n",
    "EIB_COL = \"eib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPIKE_INTERFACE'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKE_INTERFACE_COL.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: Change based on individual project data location\n",
    "\n",
    "# Spreadsheet of channel mapping\n",
    "CHANNEL_MAPPING_DF = pd.read_excel(\"../../data/rce_per_subject_channel_mapping.xlsx\")\n",
    "# Spreadsheet of tone time\n",
    "TONE_TIMESTAMP_DF = pd.read_pickle(\"../../proc/rce_tone_timestamps.pkl\")\n",
    "# TONE_TIMESTAMP_DF = pd.read_pickle(\"../../data/rce_per_trial_labeling.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>eib_mPFC</th>\n",
       "      <th>eib_vHPC</th>\n",
       "      <th>eib_BLA</th>\n",
       "      <th>eib_LH</th>\n",
       "      <th>eib_MD</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cohort  Subject  eib_mPFC  eib_vHPC  eib_BLA  eib_LH  eib_MD  \\\n",
       "0       1      6.1       NaN        15       14      13      31   \n",
       "1       1      6.2       NaN        15       14      13      31   \n",
       "2       1      6.3       NaN        15       14      13      31   \n",
       "3       1      6.4       NaN        15       14      13      31   \n",
       "4       2      1.1       NaN        16       17      18      19   \n",
       "\n",
       "   spike_interface_mPFC  spike_interface_vHPC  spike_interface_BLA  \\\n",
       "0                  21.0                  15.0                 14.0   \n",
       "1                   NaN                   NaN                  NaN   \n",
       "2                   NaN                   NaN                  NaN   \n",
       "3                   NaN                   NaN                  NaN   \n",
       "4                   5.0                  31.0                 30.0   \n",
       "\n",
       "   spike_interface_LH  spike_interface_MD  \n",
       "0                13.0                16.0  \n",
       "1                 NaN                 NaN  \n",
       "2                 NaN                 NaN  \n",
       "3                 NaN                 NaN  \n",
       "4                29.0                28.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHANNEL_MAPPING_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: Change based on individual project data location\n",
    "# Where all the recording files are being saved\n",
    "ALL_SESSION_DIR = glob.glob(\"/blue/npadillacoreano/ryoi360/reward_competition_extention/data/standard/2023_06_16/*.rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/blue/npadillacoreano/ryoi360/reward_competition_extention/data/standard/2023_06_16/20230616_111904_standard_comp_to_training_D4_subj_1-4_and_1-2.rec']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_SESSION_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TONE_TIMESTAMPS_CSV = \"rce_tone_timestamps.csv\"\n",
    "TONE_TIMESTAMPS_PKL = \"rce_tone_timestamps.pkl\"\n",
    "FULL_LFP_TRACES_PKL = \"full_baseline_and_trial_lfp_traces.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20230616_111904_standard_comp_to_training_D4_subj_1-4_t4b3L_box1_merged\n",
      "An exception occurred: stream_id trodes is not in ['ECU']\n",
      "20230616_111904_standard_comp_to_training_D4_subj_1-2_t2b2L_box2_merged\n"
     ]
    }
   ],
   "source": [
    "recording_name_to_all_ch_lfp = {}\n",
    "# Going through all the recording sessions \n",
    "for session_dir in ALL_SESSION_DIR:\n",
    "    # Going through all the recordings in each session\n",
    "    for recording_path in glob.glob(os.path.join(session_dir, RECORDING_EXTENTION)):\n",
    "        try:\n",
    "            recording_basename = os.path.splitext(os.path.basename(recording_path))[0]\n",
    "            # checking to see if the recording has an ECU component\n",
    "            # if it doesn't, then the next one be extracted\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=ECU_STREAM_ID)\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=TRODES_STREAM_ID)\n",
    "            print(recording_basename)\n",
    "            # Preprocessing the LFP\n",
    "            current_recording = sp.bandpass_filter(current_recording, freq_min=LFP_FREQ_MIN, freq_max=LFP_FREQ_MAX)\n",
    "            current_recording = sp.notch_filter(current_recording, freq=ELECTRIC_NOISE_FREQ)\n",
    "            current_recording = sp.resample(current_recording, resample_rate=LFP_SAMPLING_RATE)\n",
    "            current_recording = sp.zscore(current_recording)\n",
    "            recording_name_to_all_ch_lfp[recording_basename] = current_recording\n",
    "        except Exception as error:\n",
    "            # handle the exception\n",
    "            print(\"An exception occurred:\", error) # An exception occurred: division by zero\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>time_stamp_index</th>\n",
       "      <th>video_file</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>reward_frame</th>\n",
       "      <th>video_number</th>\n",
       "      <th>subject_info</th>\n",
       "      <th>competition_closeness</th>\n",
       "      <th>...</th>\n",
       "      <th>video_name</th>\n",
       "      <th>baseline_lfp_index_range</th>\n",
       "      <th>trial_lfp_index_range</th>\n",
       "      <th>baseline_ephys_index_range</th>\n",
       "      <th>trial_ephys_index_range</th>\n",
       "      <th>baseline_videoframe_range</th>\n",
       "      <th>trial_videoframe_range</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>trial_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781115</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>982229</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>980</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-3_t3b3L_box2</td>\n",
       "      <td>lose_non_comp</td>\n",
       "      <td>...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>(39111, 49111)</td>\n",
       "      <td>(49111, 59111)</td>\n",
       "      <td>(782229, 982229)</td>\n",
       "      <td>(982229, 1182229)</td>\n",
       "      <td>(760, 980)</td>\n",
       "      <td>(980, 1200)</td>\n",
       "      <td>(1.3, 1.4)</td>\n",
       "      <td>1.3</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12181113</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>3382227</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>3376</td>\n",
       "      <td>3456.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-3_t3b3L_box2</td>\n",
       "      <td>win_non_comp</td>\n",
       "      <td>...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>(159111, 169111)</td>\n",
       "      <td>(169111, 179111)</td>\n",
       "      <td>(3182227, 3382227)</td>\n",
       "      <td>(3382227, 3582227)</td>\n",
       "      <td>(3156, 3376)</td>\n",
       "      <td>(3376, 3596)</td>\n",
       "      <td>(1.3, 1.4)</td>\n",
       "      <td>1.3</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14481111</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>5682225</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>5671</td>\n",
       "      <td>5751.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-3_t3b3L_box2</td>\n",
       "      <td>lose_non_comp</td>\n",
       "      <td>...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>(274111, 284111)</td>\n",
       "      <td>(284111, 294111)</td>\n",
       "      <td>(5482225, 5682225)</td>\n",
       "      <td>(5682225, 5882225)</td>\n",
       "      <td>(5451, 5671)</td>\n",
       "      <td>(5671, 5891)</td>\n",
       "      <td>(1.3, 1.4)</td>\n",
       "      <td>1.3</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16281110</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>7482224</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>7468</td>\n",
       "      <td>7548.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-3_t3b3L_box2</td>\n",
       "      <td>lose_non_comp</td>\n",
       "      <td>...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>(364111, 374111)</td>\n",
       "      <td>(374111, 384111)</td>\n",
       "      <td>(7282224, 7482224)</td>\n",
       "      <td>(7482224, 7682224)</td>\n",
       "      <td>(7248, 7468)</td>\n",
       "      <td>(7468, 7688)</td>\n",
       "      <td>(1.3, 1.4)</td>\n",
       "      <td>1.3</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17381106</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>8582220</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>8566</td>\n",
       "      <td>8646.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-3_t3b3L_box2</td>\n",
       "      <td>lose_non_comp</td>\n",
       "      <td>...</td>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>(419111, 429111)</td>\n",
       "      <td>(429111, 439111)</td>\n",
       "      <td>(8382220, 8582220)</td>\n",
       "      <td>(8582220, 8782220)</td>\n",
       "      <td>(8346, 8566)</td>\n",
       "      <td>(8566, 8786)</td>\n",
       "      <td>(1.3, 1.4)</td>\n",
       "      <td>1.3</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>28120638</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>24708627</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>24552</td>\n",
       "      <td>24632.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-2vs1-1and2-1</td>\n",
       "      <td>win_comp</td>\n",
       "      <td>...</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>(1225431, 1235431)</td>\n",
       "      <td>(1235431, 1245431)</td>\n",
       "      <td>(24508627, 24708627)</td>\n",
       "      <td>(24708627, 24908627)</td>\n",
       "      <td>(24332, 24552)</td>\n",
       "      <td>(24552, 24772)</td>\n",
       "      <td>(1.1vs2.2, 1.2vs2.1)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>29720656</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>26308645</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>26149</td>\n",
       "      <td>26229.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-2vs1-1and2-1</td>\n",
       "      <td>lose_comp</td>\n",
       "      <td>...</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>(1305432, 1315432)</td>\n",
       "      <td>(1315432, 1325432)</td>\n",
       "      <td>(26108645, 26308645)</td>\n",
       "      <td>(26308645, 26508645)</td>\n",
       "      <td>(25929, 26149)</td>\n",
       "      <td>(26149, 26369)</td>\n",
       "      <td>(1.1vs2.2, 1.2vs2.1)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>31120674</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>27708663</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>27547</td>\n",
       "      <td>27627.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-2vs1-1and2-1</td>\n",
       "      <td>lose_comp</td>\n",
       "      <td>...</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>(1375433, 1385433)</td>\n",
       "      <td>(1385433, 1395433)</td>\n",
       "      <td>(27508663, 27708663)</td>\n",
       "      <td>(27708663, 27908663)</td>\n",
       "      <td>(27327, 27547)</td>\n",
       "      <td>(27547, 27767)</td>\n",
       "      <td>(1.1vs2.2, 1.2vs2.1)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>33320701</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>29908690</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>29743</td>\n",
       "      <td>29823.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-2vs1-1and2-1</td>\n",
       "      <td>lose_comp</td>\n",
       "      <td>...</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>(1485434, 1495434)</td>\n",
       "      <td>(1495434, 1505434)</td>\n",
       "      <td>(29708690, 29908690)</td>\n",
       "      <td>(29908690, 30108690)</td>\n",
       "      <td>(29523, 29743)</td>\n",
       "      <td>(29743, 29963)</td>\n",
       "      <td>(1.1vs2.2, 1.2vs2.1)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>34520719</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>31108708</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>30940</td>\n",
       "      <td>31020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1-2vs1-1and2-1</td>\n",
       "      <td>win_comp</td>\n",
       "      <td>...</td>\n",
       "      <td>20230628_111202_standard_comp_to_novel_agent_D...</td>\n",
       "      <td>(1545435, 1555435)</td>\n",
       "      <td>(1555435, 1565435)</td>\n",
       "      <td>(30908708, 31108708)</td>\n",
       "      <td>(31108708, 31308708)</td>\n",
       "      <td>(30720, 30940)</td>\n",
       "      <td>(30940, 31160)</td>\n",
       "      <td>(1.1vs2.2, 1.2vs2.1)</td>\n",
       "      <td>1.2</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>770 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time                                      recording_dir  \\\n",
       "0     9781115  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "1    12181113  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "2    14481111  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "3    16281110  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "4    17381106  20230612_101430_standard_comp_to_training_D1_s...   \n",
       "..        ...                                                ...   \n",
       "765  28120638  20230628_111202_standard_comp_to_novel_agent_D...   \n",
       "766  29720656  20230628_111202_standard_comp_to_novel_agent_D...   \n",
       "767  31120674  20230628_111202_standard_comp_to_novel_agent_D...   \n",
       "768  33320701  20230628_111202_standard_comp_to_novel_agent_D...   \n",
       "769  34520719  20230628_111202_standard_comp_to_novel_agent_D...   \n",
       "\n",
       "                                        recording_file  time_stamp_index  \\\n",
       "0    20230612_101430_standard_comp_to_training_D1_s...            982229   \n",
       "1    20230612_101430_standard_comp_to_training_D1_s...           3382227   \n",
       "2    20230612_101430_standard_comp_to_training_D1_s...           5682225   \n",
       "3    20230612_101430_standard_comp_to_training_D1_s...           7482224   \n",
       "4    20230612_101430_standard_comp_to_training_D1_s...           8582220   \n",
       "..                                                 ...               ...   \n",
       "765  20230628_111202_standard_comp_to_novel_agent_D...          24708627   \n",
       "766  20230628_111202_standard_comp_to_novel_agent_D...          26308645   \n",
       "767  20230628_111202_standard_comp_to_novel_agent_D...          27708663   \n",
       "768  20230628_111202_standard_comp_to_novel_agent_D...          29908690   \n",
       "769  20230628_111202_standard_comp_to_novel_agent_D...          31108708   \n",
       "\n",
       "                                            video_file  video_frame  \\\n",
       "0    20230612_101430_standard_comp_to_training_D1_s...          980   \n",
       "1    20230612_101430_standard_comp_to_training_D1_s...         3376   \n",
       "2    20230612_101430_standard_comp_to_training_D1_s...         5671   \n",
       "3    20230612_101430_standard_comp_to_training_D1_s...         7468   \n",
       "4    20230612_101430_standard_comp_to_training_D1_s...         8566   \n",
       "..                                                 ...          ...   \n",
       "765  20230628_111202_standard_comp_to_novel_agent_D...        24552   \n",
       "766  20230628_111202_standard_comp_to_novel_agent_D...        26149   \n",
       "767  20230628_111202_standard_comp_to_novel_agent_D...        27547   \n",
       "768  20230628_111202_standard_comp_to_novel_agent_D...        29743   \n",
       "769  20230628_111202_standard_comp_to_novel_agent_D...        30940   \n",
       "\n",
       "     reward_frame  video_number    subject_info competition_closeness  ...  \\\n",
       "0          1060.0           1.0  1-3_t3b3L_box2         lose_non_comp  ...   \n",
       "1          3456.0           1.0  1-3_t3b3L_box2          win_non_comp  ...   \n",
       "2          5751.0           1.0  1-3_t3b3L_box2         lose_non_comp  ...   \n",
       "3          7548.0           1.0  1-3_t3b3L_box2         lose_non_comp  ...   \n",
       "4          8646.0           1.0  1-3_t3b3L_box2         lose_non_comp  ...   \n",
       "..            ...           ...             ...                   ...  ...   \n",
       "765       24632.0           1.0  1-2vs1-1and2-1              win_comp  ...   \n",
       "766       26229.0           1.0  1-2vs1-1and2-1             lose_comp  ...   \n",
       "767       27627.0           1.0  1-2vs1-1and2-1             lose_comp  ...   \n",
       "768       29823.0           1.0  1-2vs1-1and2-1             lose_comp  ...   \n",
       "769       31020.0           1.0  1-2vs1-1and2-1              win_comp  ...   \n",
       "\n",
       "                                            video_name  \\\n",
       "0    20230612_101430_standard_comp_to_training_D1_s...   \n",
       "1    20230612_101430_standard_comp_to_training_D1_s...   \n",
       "2    20230612_101430_standard_comp_to_training_D1_s...   \n",
       "3    20230612_101430_standard_comp_to_training_D1_s...   \n",
       "4    20230612_101430_standard_comp_to_training_D1_s...   \n",
       "..                                                 ...   \n",
       "765  20230628_111202_standard_comp_to_novel_agent_D...   \n",
       "766  20230628_111202_standard_comp_to_novel_agent_D...   \n",
       "767  20230628_111202_standard_comp_to_novel_agent_D...   \n",
       "768  20230628_111202_standard_comp_to_novel_agent_D...   \n",
       "769  20230628_111202_standard_comp_to_novel_agent_D...   \n",
       "\n",
       "    baseline_lfp_index_range trial_lfp_index_range baseline_ephys_index_range  \\\n",
       "0             (39111, 49111)        (49111, 59111)           (782229, 982229)   \n",
       "1           (159111, 169111)      (169111, 179111)         (3182227, 3382227)   \n",
       "2           (274111, 284111)      (284111, 294111)         (5482225, 5682225)   \n",
       "3           (364111, 374111)      (374111, 384111)         (7282224, 7482224)   \n",
       "4           (419111, 429111)      (429111, 439111)         (8382220, 8582220)   \n",
       "..                       ...                   ...                        ...   \n",
       "765       (1225431, 1235431)    (1235431, 1245431)       (24508627, 24708627)   \n",
       "766       (1305432, 1315432)    (1315432, 1325432)       (26108645, 26308645)   \n",
       "767       (1375433, 1385433)    (1385433, 1395433)       (27508663, 27708663)   \n",
       "768       (1485434, 1495434)    (1495434, 1505434)       (29708690, 29908690)   \n",
       "769       (1545435, 1555435)    (1555435, 1565435)       (30908708, 31108708)   \n",
       "\n",
       "    trial_ephys_index_range baseline_videoframe_range trial_videoframe_range  \\\n",
       "0         (982229, 1182229)                (760, 980)            (980, 1200)   \n",
       "1        (3382227, 3582227)              (3156, 3376)           (3376, 3596)   \n",
       "2        (5682225, 5882225)              (5451, 5671)           (5671, 5891)   \n",
       "3        (7482224, 7682224)              (7248, 7468)           (7468, 7688)   \n",
       "4        (8582220, 8782220)              (8346, 8566)           (8566, 8786)   \n",
       "..                      ...                       ...                    ...   \n",
       "765    (24708627, 24908627)            (24332, 24552)         (24552, 24772)   \n",
       "766    (26308645, 26508645)            (25929, 26149)         (26149, 26369)   \n",
       "767    (27708663, 27908663)            (27327, 27547)         (27547, 27767)   \n",
       "768    (29908690, 30108690)            (29523, 29743)         (29743, 29963)   \n",
       "769    (31108708, 31308708)            (30720, 30940)         (30940, 31160)   \n",
       "\n",
       "             all_subjects current_subject trial_outcome  \n",
       "0              (1.3, 1.4)             1.3          lose  \n",
       "1              (1.3, 1.4)             1.3           win  \n",
       "2              (1.3, 1.4)             1.3          lose  \n",
       "3              (1.3, 1.4)             1.3          lose  \n",
       "4              (1.3, 1.4)             1.3          lose  \n",
       "..                    ...             ...           ...  \n",
       "765  (1.1vs2.2, 1.2vs2.1)             1.2           win  \n",
       "766  (1.1vs2.2, 1.2vs2.1)             1.2          lose  \n",
       "767  (1.1vs2.2, 1.2vs2.1)             1.2          lose  \n",
       "768  (1.1vs2.2, 1.2vs2.1)             1.2          lose  \n",
       "769  (1.1vs2.2, 1.2vs2.1)             1.2           win  \n",
       "\n",
       "[770 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TONE_TIMESTAMP_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RECORDING_TO_SUBJECT = TONE_TIMESTAMP_DF.drop_duplicates(subset=[RECORDING_FILE_COL, CURRENT_SUBJECT_COL])[[RECORDING_DIR_COL, RECORDING_FILE_COL, CURRENT_SUBJECT_COL]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RECORDING_TO_SUBJECT = RECORDING_TO_SUBJECT[RECORDING_TO_SUBJECT[RECORDING_FILE_COL].isin(recording_name_to_all_ch_lfp)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>current_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       recording_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                      recording_file current_subject  \n",
       "0  20230616_111904_standard_comp_to_training_D4_s...             1.4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RECORDING_TO_SUBJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the channel mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF = CHANNEL_MAPPING_DF.drop(columns=[col for col in CHANNEL_MAPPING_DF.columns if \"eib\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding all the brain region to ch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF[SUBJECT_COL] = CHANNEL_MAPPING_DF[SUBJECT_COL].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merging the recording and the channel dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RECORDING_TO_SUBJECT = pd.merge(RECORDING_TO_SUBJECT, CHANNEL_MAPPING_DF, left_on=CURRENT_SUBJECT_COL, right_on=SUBJECT_COL, how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       recording_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                      recording_file current_subject  Cohort  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...             1.4       2   \n",
       "\n",
       "  Subject  spike_interface_mPFC  spike_interface_vHPC  spike_interface_BLA  \\\n",
       "0     1.4                  15.0                  31.0                 30.0   \n",
       "\n",
       "   spike_interface_LH  spike_interface_MD  \n",
       "0                29.0                28.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RECORDING_TO_SUBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_convert = [col for col in RECORDING_TO_SUBJECT.columns if \"spike_interface\" in col]\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    RECORDING_TO_SUBJECT[col] = RECORDING_TO_SUBJECT[col].astype(int).astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the channel specific LFP traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linking up all LFP calculations with all the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDING_TO_SUBJECT[ALL_CH_LFP_COL] = RECORDING_TO_SUBJECT[RECORDING_FILE_COL].map(recording_name_to_all_ch_lfp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "      <th>all_ch_lfp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       recording_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                      recording_file current_subject  Cohort  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...             1.4       2   \n",
       "\n",
       "  Subject spike_interface_mPFC spike_interface_vHPC spike_interface_BLA  \\\n",
       "0     1.4                   15                   31                  30   \n",
       "\n",
       "  spike_interface_LH spike_interface_MD  \\\n",
       "0                 29                 28   \n",
       "\n",
       "                                          all_ch_lfp  \n",
       "0  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RECORDING_TO_SUBJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extracting the traces for each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spike_interface_mPFC\n",
      "spike_interface_vHPC\n",
      "spike_interface_BLA\n",
      "spike_interface_LH\n",
      "spike_interface_MD\n"
     ]
    }
   ],
   "source": [
    "for col in columns_to_convert:\n",
    "    print(col)\n",
    "    brain_region = col.strip(SPIKE_INTERFACE_COL).strip(\"_\")\n",
    "    trace_column = \"{}_lfp_trace\".format(brain_region)\n",
    "    RECORDING_TO_SUBJECT[trace_column] = RECORDING_TO_SUBJECT.apply(lambda row: row[ALL_CH_LFP_COL].get_traces(channel_ids=[row[col]]).T[0], axis=1)\n",
    "                                                                                                                                                       \n",
    "                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDING_TO_SUBJECT = RECORDING_TO_SUBJECT.drop(columns=[ALL_CH_LFP_COL], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECORDING_TO_SUBJECT = RECORDING_TO_SUBJECT.drop(columns=[col for col in RECORDING_TO_SUBJECT if SPIKE_INTERFACE_COL in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>mPFC_lfp_trace</th>\n",
       "      <th>vHPC_lfp_trace</th>\n",
       "      <th>BLA_lfp_trace</th>\n",
       "      <th>LH_lfp_trace</th>\n",
       "      <th>MD_lfp_trace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>[-0.30157474, -0.25617638, -0.045398347, 0.252...</td>\n",
       "      <td>[0.316397, 0.54940253, 0.72599626, 0.66713166,...</td>\n",
       "      <td>[0.20018278, 0.35167247, 0.5121794, 0.6059587,...</td>\n",
       "      <td>[0.03897052, 0.044965982, 0.14688888, 0.350734...</td>\n",
       "      <td>[0.6358626, 0.98053575, 1.1825856, 1.224184, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       recording_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                      recording_file current_subject  Cohort  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...             1.4       2   \n",
       "\n",
       "  Subject                                     mPFC_lfp_trace  \\\n",
       "0     1.4  [-0.30157474, -0.25617638, -0.045398347, 0.252...   \n",
       "\n",
       "                                      vHPC_lfp_trace  \\\n",
       "0  [0.316397, 0.54940253, 0.72599626, 0.66713166,...   \n",
       "\n",
       "                                       BLA_lfp_trace  \\\n",
       "0  [0.20018278, 0.35167247, 0.5121794, 0.6059587,...   \n",
       "\n",
       "                                        LH_lfp_trace  \\\n",
       "0  [0.03897052, 0.044965982, 0.14688888, 0.350734...   \n",
       "\n",
       "                                        MD_lfp_trace  \n",
       "0  [0.6358626, 0.98053575, 1.1825856, 1.224184, 1...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RECORDING_TO_SUBJECT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_dir</th>\n",
       "      <th>recording_file</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>mPFC_lfp_trace</th>\n",
       "      <th>vHPC_lfp_trace</th>\n",
       "      <th>BLA_lfp_trace</th>\n",
       "      <th>LH_lfp_trace</th>\n",
       "      <th>MD_lfp_trace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>[-0.30157474, -0.25617638, -0.045398347, 0.252...</td>\n",
       "      <td>[0.316397, 0.54940253, 0.72599626, 0.66713166,...</td>\n",
       "      <td>[0.20018278, 0.35167247, 0.5121794, 0.6059587,...</td>\n",
       "      <td>[0.03897052, 0.044965982, 0.14688888, 0.350734...</td>\n",
       "      <td>[0.6358626, 0.98053575, 1.1825856, 1.224184, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       recording_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                      recording_file current_subject  Cohort  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...             1.4       2   \n",
       "\n",
       "  Subject                                     mPFC_lfp_trace  \\\n",
       "0     1.4  [-0.30157474, -0.25617638, -0.045398347, 0.252...   \n",
       "\n",
       "                                      vHPC_lfp_trace  \\\n",
       "0  [0.316397, 0.54940253, 0.72599626, 0.66713166,...   \n",
       "\n",
       "                                       BLA_lfp_trace  \\\n",
       "0  [0.20018278, 0.35167247, 0.5121794, 0.6059587,...   \n",
       "\n",
       "                                        LH_lfp_trace  \\\n",
       "0  [0.03897052, 0.044965982, 0.14688888, 0.350734...   \n",
       "\n",
       "                                        MD_lfp_trace  \n",
       "0  [0.6358626, 0.98053575, 1.1825856, 1.224184, 1...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RECORDING_TO_SUBJECT.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['recording_dir', 'recording_file', 'current_subject', 'Cohort',\n",
       "       'Subject', 'mPFC_lfp_trace', 'vHPC_lfp_trace', 'BLA_lfp_trace',\n",
       "       'LH_lfp_trace', 'MD_lfp_trace'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RECORDING_TO_SUBJECT.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RECORDING_TO_SUBJECT.to_pickle(os.path.join(OUTPUT_DIR, FULL_LFP_TRACES_PKL))"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "spike_interface_0_99_0",
   "language": "python",
   "name": "spike_interface_0_99_0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
