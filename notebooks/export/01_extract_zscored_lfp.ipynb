{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c3a02adc9e884466bc8c79db549cc3d2",
    "deepnote_cell_type": "text-cell-h1",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true,
       "underline": true
      },
      "toCodePoint": 17,
      "type": "marks"
     }
    ]
   },
   "source": [
    "# Notebook 1: Extract Z-scored LFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This Jupyter notebook focuses on extracting local field potential (LFP) traces from Spikegadgets `.rec` files, specifically for neuroscience research related to social competition trials. The notebook includes procedures for preprocessing and synchronizing raw electrophysiology data with corresponding video data and computes various metrics, including Z-scored LFPs.\n",
    "\n",
    "### Inputs & Data Sources\n",
    "- **Electrophysiology and LFP Parameters**: Constants like `EPHYS_SAMPLING_RATE`, `LFP_SAMPLING_RATE`, `TRIAL_DURATION`, etc., define basic parameters for LFP data processing.\n",
    "- **Recording Information**: Stream IDs (`ECU_STREAM_ID`, `TRODES_STREAM_ID`), recording extension (`RECORDING_EXTENSION`), and paths to recording directories (`ALL_SESSION_DIR`).\n",
    "- **DataFrames for Mapping and Timestamps**: `CHANNEL_MAPPING_DF` for channel mapping, and `TONE_TIMESTAMP_DF` for tone timestamps, loaded from external sources.\n",
    "- **Constants for DataFrame Columns**: Names for various columns in the DataFrame, defined in an all-caps snake case format, such as `EPHYS_INDEX_COL`, `LFP_INDEX_COL`, etc.\n",
    "\n",
    "### Output & Utility\n",
    "- **Processed Data**: The notebook outputs processed data, particularly the Z-scored LFP traces, which are critical for further analysis in neuroscience research.\n",
    "- **Data Files**: Outputs are saved in various formats (`CSV`, `Pickle`) in a specified output directory (`OUTPUT_DIR`).\n",
    "- **Visualization**: While not explicitly mentioned, the notebook has the potential for data visualization (plots) based on processed LFP data.\n",
    "\n",
    "### Processing Workflow\n",
    "1. **LFP Extraction and Preprocessing**: \n",
    "    - Iterates through recording sessions to process `.rec` files.\n",
    "    - Applies a series of preprocessing steps like bandpass filtering, notch filtering, resampling, and Z-scoring on the LFP data.\n",
    "    - Exception handling for cases where the recording doesn't contain specified stream IDs.\n",
    "\n",
    "2. **DataFrame Manipulation and Merging**:\n",
    "    - Filtering `TONE_TIMESTAMP_DF` for trials with obtained LFP.\n",
    "    - Addition of trial numbers and merging with `CHANNEL_MAPPING_DF`.\n",
    "    - Dropping unnecessary columns and restructuring for analysis.\n",
    "\n",
    "3. **LFP Trace Extraction for Each Trial and Brain Region**: \n",
    "    - Linking LFP calculations with trials.\n",
    "    - Creating new rows for each brain region, extracting baseline, trial, and combined LFP traces.\n",
    "    - Results in a comprehensive DataFrame that combines trial information with corresponding LFP traces.\n",
    "\n",
    "4. **Data Storage**:\n",
    "    - Saving processed DataFrame in both `CSV` and `Pickle` formats for easy access and future use.\n",
    "\n",
    "### Usage Notes\n",
    "- The notebook is project-specific and tailored for a particular dataset structure, requiring modifications for different data formats.\n",
    "- Users should ensure file paths and directory names match their project's structure and adjust constants and parameters as needed for their specific analysis requirements.\n",
    "- The notebook forms a part of a larger research framework, thus necessitating compatibility checks with other components of the project.\n",
    "\n",
    "### Dependencies\n",
    "- Python Libraries: `sys`, `os`, `glob`, `numpy`, `pandas`, `spikeinterface`\n",
    "- External Data: Channel mapping and tone timestamp files, along with Spikegadgets `.rec` files.\n",
    "\n",
    "### Customization and Scalability\n",
    "- The notebook's modular design allows for easy adaptation to different datasets or extensions to include additional processing steps.\n",
    "- Functions and processing steps are clearly demarcated, facilitating straightforward updates or enhancements.\n",
    "\n",
    "### Conclusion\n",
    "This notebook is a vital tool in the preprocessing and analysis of LFP data from Spikegadgets recordings, integral to neuroscience research focused on social competition trials. It offers a structured approach to handle, process, and store electrophysiological data, ensuring reproducibility and efficiency in research workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "git_repo = git.Repo(\".\", search_parent_directories=True)\n",
    "git_root = git_repo.git.rev_parse(\"--show-toplevel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nancy/projects/reward_competition_extention'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.join(git_root, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "03b495cefa6a4798a44c7f2e4c6a3ea7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 21,
    "execution_start": 1691424003626,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports of all used packages and libraries\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spikeinterface.extractors as se\n",
    "import spikeinterface.preprocessing as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utilities import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d290bac2c17940bfbc0f9296beaf70e5",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Inputs & Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e528ce19c608425292151930d380f49f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Explanation of each input and where it comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPHYS_SAMPLING_RATE = 20000\n",
    "LFP_SAMPLING_RATE = 1000\n",
    "LFP_RESAMPLE_RATIO = EPHYS_SAMPLING_RATE / LFP_SAMPLING_RATE\n",
    "TRIAL_DURATION = 10\n",
    "FRAME_RATE = 22\n",
    "ECU_STREAM_ID = \"ECU\"\n",
    "TRODES_STREAM_ID = \"trodes\"\n",
    "LFP_FREQ_MIN = 0.5\n",
    "LFP_FREQ_MAX = 300\n",
    "ELECTRIC_NOISE_FREQ = 60\n",
    "RECORDING_EXTENTION = \"*.rec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPHYS_INDEX_COL = \"time_stamp_index\"\n",
    "LFP_INDEX_COL = \"lfp_index\"\n",
    "EPHYS_TIMESTAMP_COL = \"time\"\n",
    "RECORDING_FILE_COL = \"recording_file\"\n",
    "RECORDING_DIR_COL = \"recording_dir\"\n",
    "BASELINE_LFP_INDEX_RANGE_COL = \"baseline_lfp_index_range\"\n",
    "TRIAL_LFP_INDEX_RANGE_COL = \"trial_lfp_index_range\"\n",
    "BASELINE_EPHYS_INDEX_RANGE_COL = \"baseline_ephys_index_range\"\n",
    "TRIAL_EPHYS_INDEX_RANGE_COL = \"trial_ephys_index_range\"\n",
    "BASELINE_VIDEOFRAME_RANGE_COL = \"baseline_videoframe_range\"\n",
    "TRIAL_VIDEOFRAME_RANGE_COL = \"trial_videoframe_range\"\n",
    "CURRENT_SUBJECT_COL = \"current_subject\"\n",
    "ALL_CH_LFP_COL = \"all_ch_lfp\"\n",
    "SUBJECT_COL = \"Subject\"\n",
    "TRIAL_NUMBER_COL = \"trial_number\"\n",
    "SPIKE_INTERFACE_COL = \"spike_interface\"\n",
    "EIB_COL = \"eib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFP_TRACE_COLUMNS = [\"session_dir\", \"recording\", \"metadata_dir\", \"metadata_file\", \"first_dtype_name\", \"first_item_data\", \"last_dtype_name\", \"last_item_data\", 'all_subjects', 'current_subject', 'filename']\n",
    "VIDEO_COLUMNS = ['session_dir', 'recording', 'metadata_dir', 'metadata_file',\n",
    "      'session_path', 'first_dtype_name', 'first_item_data',\n",
    "       'all_subjects', 'current_subject', 'filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: Change based on individual project data location\n",
    "\n",
    "# Spreadsheet of channel mapping\n",
    "CHANNEL_MAPPING_DF = pd.read_excel(os.path.join(git_root, \"data/channel_mapping.xlsx\"))\n",
    "# Spreadsheet of tone time\n",
    "SPIKEGADGETS_EXTRACTED_DF = pd.read_pickle(\"./proc/rce_pilot_2_trodes_metadata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>eib_mPFC</th>\n",
       "      <th>eib_vHPC</th>\n",
       "      <th>eib_BLA</th>\n",
       "      <th>eib_LH</th>\n",
       "      <th>eib_MD</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cohort  Subject  eib_mPFC  eib_vHPC  eib_BLA  eib_LH  eib_MD  \\\n",
       "0       1      6.1       NaN        15       14      13      31   \n",
       "1       1      6.2       NaN        15       14      13      31   \n",
       "2       1      6.3       NaN        15       14      13      31   \n",
       "3       1      6.4       NaN        15       14      13      31   \n",
       "4       2      1.1       NaN        16       17      18      19   \n",
       "\n",
       "   spike_interface_mPFC  spike_interface_vHPC  spike_interface_BLA  \\\n",
       "0                  21.0                  15.0                 14.0   \n",
       "1                   NaN                   NaN                  NaN   \n",
       "2                   NaN                   NaN                  NaN   \n",
       "3                   NaN                   NaN                  NaN   \n",
       "4                   5.0                  31.0                 30.0   \n",
       "\n",
       "   spike_interface_LH  spike_interface_MD  \n",
       "0                13.0                16.0  \n",
       "1                 NaN                 NaN  \n",
       "2                 NaN                 NaN  \n",
       "3                 NaN                 NaN  \n",
       "4                29.0                28.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHANNEL_MAPPING_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: Change based on individual project data location\n",
    "# Where all the recording files are being saved\n",
    "ALL_SESSION_DIR = glob.glob(\"/scratch/back_up/reward_competition_extention/data/standard/2023_06_16/*.rec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/back_up/reward_competition_extention/data/standard/2023_06_16/20230616_111904_standard_comp_to_training_D4_subj_1-4_and_1-2.rec']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_SESSION_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3ee4891d43a4ac287413afc552ca289",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9ccbf6cc70fd4d379fa29317f733771f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe each output that the notebook creates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fc8e8920a6944918a15fac575cdf6e78",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- Is it a plot or is it data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e639d4776a84aa9ac8ded2e14fa57db",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "- How valuable is the output and why is it valuable or useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "6cf83a5811054461a718a71673d09aab",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 373,
    "execution_start": 1691424003628,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inputs and Required data loading\n",
    "# input varaible names are in all caps snake case\n",
    "# Whenever an input changes or is used for processing \n",
    "# the vairables are all lower in snake case\n",
    "OUTPUT_DIR = r\"./proc/\" # where data is saved should always be shown in the inputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TONE_TIMESTAMPS_CSV = \"rce_tone_timestamps.csv\"\n",
    "TONE_TIMESTAMPS_PKL = \"rce_tone_timestamps.pkl\"\n",
    "FULL_LFP_TRACES_PKL = \"full_baseline_and_trial_lfp_traces.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8999d19b6b7d4d63bc90f0b0bd9ab085",
    "deepnote_cell_type": "text-cell-h2",
    "formattedRanges": []
   },
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9b36cdf08567463082b005cb0dec684b",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Describe what is done to the data here and how inputs are manipulated to generate outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "89aaba237c644628b1b37604b75e7cb1",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As much code and as many cells as required\n",
    "# includes EDA and playing with data\n",
    "# GO HAM!\n",
    "\n",
    "# Ideally functions are defined here first and then data is processed using the functions\n",
    "\n",
    "# function names are short and in snake case all lowercase\n",
    "# a function name should be unique but does not have to describe the function\n",
    "# doc strings describe functions not function names\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred: stream_id trodes is not in ['ECU']\n",
      "20230616_111904_standard_comp_to_training_D4_subj_1-4_t4b3L_box1_merged\n",
      "20230616_111904_standard_comp_to_training_D4_subj_1-2_t2b2L_box2_merged\n"
     ]
    }
   ],
   "source": [
    "recording_name_to_all_ch_lfp = {}\n",
    "# Going through all the recording sessions \n",
    "for session_dir in ALL_SESSION_DIR:\n",
    "    # Going through all the recordings in each session\n",
    "    for recording_path in glob.glob(os.path.join(session_dir, RECORDING_EXTENTION)):\n",
    "        try:\n",
    "            recording_basename = os.path.splitext(os.path.basename(recording_path))[0]\n",
    "            # checking to see if the recording has an ECU component\n",
    "            # if it doesn't, then the next one be extracted\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=ECU_STREAM_ID)\n",
    "            current_recording = se.read_spikegadgets(recording_path, stream_id=TRODES_STREAM_ID)\n",
    "            print(recording_basename)\n",
    "\n",
    "            # Preprocessing the LFP\n",
    "            current_recording = sp.bandpass_filter(current_recording, freq_min=LFP_FREQ_MIN, freq_max=LFP_FREQ_MAX)\n",
    "            current_recording = sp.notch_filter(current_recording, freq=ELECTRIC_NOISE_FREQ)\n",
    "            current_recording = sp.resample(current_recording, resample_rate=LFP_SAMPLING_RATE)            \n",
    "            current_recording = sp.zscore(current_recording)\n",
    "            recording_name_to_all_ch_lfp[recording_basename] = current_recording\n",
    "        except Exception as error:\n",
    "            # handle the exception\n",
    "            print(\"An exception occurred:\", error) # An exception occurred: division by zero\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combining LFP traces with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for rows that are the metadata for the raw recordings\n",
    "lfp_trace_condition = (SPIKEGADGETS_EXTRACTED_DF[\"recording\"].isin(recording_name_to_all_ch_lfp) & (SPIKEGADGETS_EXTRACTED_DF[\"metadata_dir\"] == \"raw\") & (SPIKEGADGETS_EXTRACTED_DF[\"metadata_file\"] == \"timestamps\"))\n",
    "SPIKEGADGETS_LFP_DF = SPIKEGADGETS_EXTRACTED_DF[lfp_trace_condition].copy().reset_index(drop=True)\n",
    "# Removing the columns that are not needed\n",
    "SPIKEGADGETS_LFP_DF = SPIKEGADGETS_LFP_DF[LFP_TRACE_COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the LFP traces to the metadata dataframe\n",
    "SPIKEGADGETS_LFP_DF[\"all_ch_lfp\"] = SPIKEGADGETS_LFP_DF[\"recording\"].map(recording_name_to_all_ch_lfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the timestamp of the LFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_LFP_DF[\"LFP_timestamps\"] = SPIKEGADGETS_LFP_DF.apply(lambda row: np.arange(row[\"first_item_data\"][0], row[\"first_item_data\"][0]+(row[\"all_ch_lfp\"].get_total_samples()*LFP_RESAMPLE_RATIO), LFP_RESAMPLE_RATIO).astype(int), axis=1)\n",
    "                                                                  \n",
    "                                                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_dir</th>\n",
       "      <th>recording</th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "      <th>first_dtype_name</th>\n",
       "      <th>first_item_data</th>\n",
       "      <th>last_dtype_name</th>\n",
       "      <th>last_item_data</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>filename</th>\n",
       "      <th>all_ch_lfp</th>\n",
       "      <th>LFP_timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "      <td>[307664, 307684, 307704, 307724, 307744, 30776...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>1.2</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "      <td>[307664, 307684, 307704, 307724, 307744, 30776...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         session_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                           recording metadata_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "\n",
       "  metadata_file first_dtype_name  \\\n",
       "0    timestamps             time   \n",
       "1    timestamps             time   \n",
       "\n",
       "                                     first_item_data last_dtype_name  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "\n",
       "                                      last_item_data all_subjects  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...        [1.2]   \n",
       "\n",
       "  current_subject                                           filename  \\\n",
       "0             1.4  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1             1.2  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                          all_ch_lfp  \\\n",
       "0  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...   \n",
       "1  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...   \n",
       "\n",
       "                                      LFP_timestamps  \n",
       "0  [307664, 307684, 307704, 307724, 307744, 30776...  \n",
       "1  [307664, 307684, 307704, 307724, 307744, 30776...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_LFP_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the channel mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF = CHANNEL_MAPPING_DF.drop(columns=[col for col in CHANNEL_MAPPING_DF.columns if \"eib\" in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in CHANNEL_MAPPING_DF.columns:\n",
    "    if \"spike_interface\" in col:\n",
    "        CHANNEL_MAPPING_DF[col] = CHANNEL_MAPPING_DF[col].fillna(0)\n",
    "        CHANNEL_MAPPING_DF[col] = CHANNEL_MAPPING_DF[col].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cohort  Subject spike_interface_mPFC spike_interface_vHPC  \\\n",
       "0       1      6.1                   21                   15   \n",
       "1       1      6.2                    0                    0   \n",
       "2       1      6.3                    0                    0   \n",
       "3       1      6.4                    0                    0   \n",
       "4       2      1.1                    5                   31   \n",
       "5       2      1.2                   10                   31   \n",
       "6       2      1.3                    9                   31   \n",
       "7       2      1.4                   15                   31   \n",
       "\n",
       "  spike_interface_BLA spike_interface_LH spike_interface_MD  \n",
       "0                  14                 13                 16  \n",
       "1                   0                  0                  0  \n",
       "2                   0                  0                  0  \n",
       "3                   0                  0                  0  \n",
       "4                  30                 29                 28  \n",
       "5                  30                 29                 28  \n",
       "6                  30                 29                 28  \n",
       "7                  30                 29                 28  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHANNEL_MAPPING_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Adding all the brain region to ch information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CHANNEL_MAPPING_DF[SUBJECT_COL] = CHANNEL_MAPPING_DF[SUBJECT_COL].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merging the recording and the channel dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_dir</th>\n",
       "      <th>recording</th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "      <th>first_dtype_name</th>\n",
       "      <th>first_item_data</th>\n",
       "      <th>last_dtype_name</th>\n",
       "      <th>last_item_data</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>filename</th>\n",
       "      <th>all_ch_lfp</th>\n",
       "      <th>LFP_timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "      <td>[307664, 307684, 307704, 307724, 307744, 30776...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>1.2</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "      <td>[307664, 307684, 307704, 307724, 307744, 30776...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         session_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                           recording metadata_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "\n",
       "  metadata_file first_dtype_name  \\\n",
       "0    timestamps             time   \n",
       "1    timestamps             time   \n",
       "\n",
       "                                     first_item_data last_dtype_name  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "\n",
       "                                      last_item_data all_subjects  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...        [1.2]   \n",
       "\n",
       "  current_subject                                           filename  \\\n",
       "0             1.4  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1             1.2  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                          all_ch_lfp  \\\n",
       "0  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...   \n",
       "1  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...   \n",
       "\n",
       "                                      LFP_timestamps  \n",
       "0  [307664, 307684, 307704, 307724, 307744, 30776...  \n",
       "1  [307664, 307684, 307704, 307724, 307744, 30776...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_LFP_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPIKEGADGETS_LFP_DF = pd.merge(SPIKEGADGETS_LFP_DF, CHANNEL_MAPPING_DF, left_on=CURRENT_SUBJECT_COL, right_on=SUBJECT_COL, how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_dir</th>\n",
       "      <th>recording</th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "      <th>first_dtype_name</th>\n",
       "      <th>first_item_data</th>\n",
       "      <th>last_dtype_name</th>\n",
       "      <th>last_item_data</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>filename</th>\n",
       "      <th>all_ch_lfp</th>\n",
       "      <th>LFP_timestamps</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Subject</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "      <td>[307664, 307684, 307704, 307724, 307744, 30776...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>1.2</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>ZScoreRecording: 32 channels - 1.0kHz - 1 segm...</td>\n",
       "      <td>[307664, 307684, 307704, 307724, 307744, 30776...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         session_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                           recording metadata_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "\n",
       "  metadata_file first_dtype_name  \\\n",
       "0    timestamps             time   \n",
       "1    timestamps             time   \n",
       "\n",
       "                                     first_item_data last_dtype_name  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "\n",
       "                                      last_item_data all_subjects  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...        [1.2]   \n",
       "\n",
       "  current_subject                                           filename  \\\n",
       "0             1.4  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1             1.2  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                          all_ch_lfp  \\\n",
       "0  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...   \n",
       "1  ZScoreRecording: 32 channels - 1.0kHz - 1 segm...   \n",
       "\n",
       "                                      LFP_timestamps  Cohort Subject  \\\n",
       "0  [307664, 307684, 307704, 307724, 307744, 30776...       2     1.4   \n",
       "1  [307664, 307684, 307704, 307724, 307744, 30776...       2     1.2   \n",
       "\n",
       "  spike_interface_mPFC spike_interface_vHPC spike_interface_BLA  \\\n",
       "0                   15                   31                  30   \n",
       "1                   10                   31                  30   \n",
       "\n",
       "  spike_interface_LH spike_interface_MD  \n",
       "0                 29                 28  \n",
       "1                 29                 28  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_LFP_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the channel specific LFP traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linking up all LFP calculations with all the trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extracting the traces for each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spike_interface_mPFC\n",
      "spike_interface_vHPC\n",
      "spike_interface_BLA\n",
      "spike_interface_LH\n",
      "spike_interface_MD\n"
     ]
    }
   ],
   "source": [
    "for col in SPIKEGADGETS_LFP_DF.columns:\n",
    "    if \"spike_interface\" in col:\n",
    "        print(col)\n",
    "        brain_region = col.strip(SPIKE_INTERFACE_COL).strip(\"_\")\n",
    "        trace_column = \"{}_lfp_trace\".format(brain_region)\n",
    "        SPIKEGADGETS_LFP_DF[trace_column] = SPIKEGADGETS_LFP_DF.apply(lambda row: row[ALL_CH_LFP_COL].get_traces(channel_ids=[row[col]]).T[0], axis=1)\n",
    "                                                                                                                                                        \n",
    "                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_dir</th>\n",
       "      <th>recording</th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "      <th>first_dtype_name</th>\n",
       "      <th>first_item_data</th>\n",
       "      <th>last_dtype_name</th>\n",
       "      <th>last_item_data</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>...</th>\n",
       "      <th>spike_interface_mPFC</th>\n",
       "      <th>spike_interface_vHPC</th>\n",
       "      <th>spike_interface_BLA</th>\n",
       "      <th>spike_interface_LH</th>\n",
       "      <th>spike_interface_MD</th>\n",
       "      <th>mPFC_lfp_trace</th>\n",
       "      <th>vHPC_lfp_trace</th>\n",
       "      <th>BLA_lfp_trace</th>\n",
       "      <th>LH_lfp_trace</th>\n",
       "      <th>MD_lfp_trace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>[-0.30157474, -0.25617638, -0.045398347, 0.252...</td>\n",
       "      <td>[0.316397, 0.54940253, 0.72599626, 0.66713166,...</td>\n",
       "      <td>[0.20018278, 0.35167247, 0.5121794, 0.6059587,...</td>\n",
       "      <td>[0.03897052, 0.044965982, 0.14688888, 0.350734...</td>\n",
       "      <td>[0.6358626, 0.98053575, 1.1825856, 1.224184, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.2]</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>[-0.031834323, 0.2765607, 0.3859912, 0.2526849...</td>\n",
       "      <td>[-0.74075544, -0.6449069, -0.5715413, -0.61414...</td>\n",
       "      <td>[-0.38670745, -0.2967755, -0.2967755, -0.42043...</td>\n",
       "      <td>[-0.18816237, 0.22000524, 0.24316369, -0.01157...</td>\n",
       "      <td>[-0.15582271, 0.20256953, 0.32500166, 0.086815...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         session_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                           recording metadata_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "\n",
       "  metadata_file first_dtype_name  \\\n",
       "0    timestamps             time   \n",
       "1    timestamps             time   \n",
       "\n",
       "                                     first_item_data last_dtype_name  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "\n",
       "                                      last_item_data all_subjects  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "1  [307664, 307665, 307666, 307667, 307668, 30766...        [1.2]   \n",
       "\n",
       "  current_subject  ... spike_interface_mPFC spike_interface_vHPC  \\\n",
       "0             1.4  ...                   15                   31   \n",
       "1             1.2  ...                   10                   31   \n",
       "\n",
       "  spike_interface_BLA  spike_interface_LH spike_interface_MD  \\\n",
       "0                  30                  29                 28   \n",
       "1                  30                  29                 28   \n",
       "\n",
       "                                      mPFC_lfp_trace  \\\n",
       "0  [-0.30157474, -0.25617638, -0.045398347, 0.252...   \n",
       "1  [-0.031834323, 0.2765607, 0.3859912, 0.2526849...   \n",
       "\n",
       "                                      vHPC_lfp_trace  \\\n",
       "0  [0.316397, 0.54940253, 0.72599626, 0.66713166,...   \n",
       "1  [-0.74075544, -0.6449069, -0.5715413, -0.61414...   \n",
       "\n",
       "                                       BLA_lfp_trace  \\\n",
       "0  [0.20018278, 0.35167247, 0.5121794, 0.6059587,...   \n",
       "1  [-0.38670745, -0.2967755, -0.2967755, -0.42043...   \n",
       "\n",
       "                                        LH_lfp_trace  \\\n",
       "0  [0.03897052, 0.044965982, 0.14688888, 0.350734...   \n",
       "1  [-0.18816237, 0.22000524, 0.24316369, -0.01157...   \n",
       "\n",
       "                                        MD_lfp_trace  \n",
       "0  [0.6358626, 0.98053575, 1.1825856, 1.224184, 1...  \n",
       "1  [-0.15582271, 0.20256953, 0.32500166, 0.086815...  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_LFP_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syncing up the video frame data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the rows that are the metadata for the video timestamps\n",
    "SPIKEGADGETS_VIDEO_DF = SPIKEGADGETS_EXTRACTED_DF[SPIKEGADGETS_EXTRACTED_DF[\"metadata_dir\"] == \"video_timestamps\"].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting only the video related columns\n",
    "SPIKEGADGETS_VIDEO_DF = SPIKEGADGETS_VIDEO_DF[VIDEO_COLUMNS].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the video timestamps into an evenly distributed array\n",
    "SPIKEGADGETS_VIDEO_DF[\"video_timestamps\"] = SPIKEGADGETS_VIDEO_DF[\"first_item_data\"].apply(lambda x: np.linspace(x.min(), x.max(), len(x)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_dir</th>\n",
       "      <th>recording</th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "      <th>session_path</th>\n",
       "      <th>first_dtype_name</th>\n",
       "      <th>first_item_data</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "      <th>filename</th>\n",
       "      <th>video_timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>video_timestamps</td>\n",
       "      <td>2</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>PosTimestamp</td>\n",
       "      <td>[309047, 309047, 310433, 310433, 311819, 31320...</td>\n",
       "      <td>[1.2, 1.4]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>[309047, 309988, 310930, 311872, 312814, 31375...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         session_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                           recording      metadata_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...  video_timestamps   \n",
       "\n",
       "  metadata_file                                       session_path  \\\n",
       "0             2  /scratch/back_up/reward_competition_extention/...   \n",
       "\n",
       "  first_dtype_name                                    first_item_data  \\\n",
       "0     PosTimestamp  [309047, 309047, 310433, 310433, 311819, 31320...   \n",
       "\n",
       "  all_subjects current_subject  \\\n",
       "0   [1.2, 1.4]             NaN   \n",
       "\n",
       "                                            filename  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                    video_timestamps  \n",
       "0  [309047, 309988, 310930, 311872, 312814, 31375...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_VIDEO_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of the video timestamps to add to the LFP dataframe\n",
    "SPIKEGADGETS_VIDEO_DICT = SPIKEGADGETS_VIDEO_DF.set_index('recording')['video_timestamps'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the video timestamps to the LFP dataframe\n",
    "SPIKEGADGETS_LFP_DF[\"video_timestamps\"] = SPIKEGADGETS_LFP_DF[\"recording\"].map(SPIKEGADGETS_VIDEO_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syncing up the ECU timestamps with the video timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_DIN_DF = SPIKEGADGETS_EXTRACTED_DF[SPIKEGADGETS_EXTRACTED_DF[\"metadata_dir\"] == \"DIO\"].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_dir</th>\n",
       "      <th>recording</th>\n",
       "      <th>metadata_dir</th>\n",
       "      <th>metadata_file</th>\n",
       "      <th>description</th>\n",
       "      <th>byte_order</th>\n",
       "      <th>original_file</th>\n",
       "      <th>clockrate</th>\n",
       "      <th>trodes_version</th>\n",
       "      <th>compile_date</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>display_order</th>\n",
       "      <th>clock rate</th>\n",
       "      <th>session_path</th>\n",
       "      <th>first_dtype_name</th>\n",
       "      <th>first_item_data</th>\n",
       "      <th>last_dtype_name</th>\n",
       "      <th>last_item_data</th>\n",
       "      <th>all_subjects</th>\n",
       "      <th>current_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>raw</td>\n",
       "      <td>timestamps</td>\n",
       "      <td>Raw timestamps</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 307665, 307666, 307667, 307668, 30766...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din3</td>\n",
       "      <td>State change data for one digital channel. Dis...</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>ECU_Din3</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 32080654, 32081454, 32082454, 3208385...</td>\n",
       "      <td>state</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din2</td>\n",
       "      <td>State change data for one digital channel. Dis...</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>ECU_Din2</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 646678, 647879, 648676, 693876, 69427...</td>\n",
       "      <td>state</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din1</td>\n",
       "      <td>State change data for one digital channel. Dis...</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>ECU_Din1</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664, 395679, 595679, 2795675, 2995676, 509...</td>\n",
       "      <td>state</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>DIO</td>\n",
       "      <td>dio_ECU_Din4</td>\n",
       "      <td>State change data for one digital channel. Dis...</td>\n",
       "      <td>little endian</td>\n",
       "      <td>20230616_111904_standard_comp_to_training_D4_s...</td>\n",
       "      <td>20000</td>\n",
       "      <td>2.4.0</td>\n",
       "      <td>May 24 2023</td>\n",
       "      <td>...</td>\n",
       "      <td>ECU_Din4</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/scratch/back_up/reward_competition_extention/...</td>\n",
       "      <td>time</td>\n",
       "      <td>[307664]</td>\n",
       "      <td>state</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[1.4]</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         session_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "2  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "3  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "4  20230616_111904_standard_comp_to_training_D4_s...   \n",
       "\n",
       "                                           recording metadata_dir  \\\n",
       "0  20230616_111904_standard_comp_to_training_D4_s...          raw   \n",
       "1  20230616_111904_standard_comp_to_training_D4_s...          DIO   \n",
       "2  20230616_111904_standard_comp_to_training_D4_s...          DIO   \n",
       "3  20230616_111904_standard_comp_to_training_D4_s...          DIO   \n",
       "4  20230616_111904_standard_comp_to_training_D4_s...          DIO   \n",
       "\n",
       "  metadata_file                                        description  \\\n",
       "0    timestamps                                     Raw timestamps   \n",
       "1  dio_ECU_Din3  State change data for one digital channel. Dis...   \n",
       "2  dio_ECU_Din2  State change data for one digital channel. Dis...   \n",
       "3  dio_ECU_Din1  State change data for one digital channel. Dis...   \n",
       "4  dio_ECU_Din4  State change data for one digital channel. Dis...   \n",
       "\n",
       "      byte_order                                      original_file clockrate  \\\n",
       "0  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "1  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "2  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "3  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "4  little endian  20230616_111904_standard_comp_to_training_D4_s...     20000   \n",
       "\n",
       "  trodes_version compile_date  ...        id display_order clock rate  \\\n",
       "0          2.4.0  May 24 2023  ...       NaN           NaN        NaN   \n",
       "1          2.4.0  May 24 2023  ...  ECU_Din3             8        NaN   \n",
       "2          2.4.0  May 24 2023  ...  ECU_Din2             6        NaN   \n",
       "3          2.4.0  May 24 2023  ...  ECU_Din1             7        NaN   \n",
       "4          2.4.0  May 24 2023  ...  ECU_Din4             9        NaN   \n",
       "\n",
       "                                        session_path first_dtype_name  \\\n",
       "0  /scratch/back_up/reward_competition_extention/...             time   \n",
       "1  /scratch/back_up/reward_competition_extention/...             time   \n",
       "2  /scratch/back_up/reward_competition_extention/...             time   \n",
       "3  /scratch/back_up/reward_competition_extention/...             time   \n",
       "4  /scratch/back_up/reward_competition_extention/...             time   \n",
       "\n",
       "                                     first_item_data last_dtype_name  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...            time   \n",
       "1  [307664, 32080654, 32081454, 32082454, 3208385...           state   \n",
       "2  [307664, 646678, 647879, 648676, 693876, 69427...           state   \n",
       "3  [307664, 395679, 595679, 2795675, 2995676, 509...           state   \n",
       "4                                           [307664]           state   \n",
       "\n",
       "                                      last_item_data all_subjects  \\\n",
       "0  [307664, 307665, 307666, 307667, 307668, 30766...        [1.4]   \n",
       "1  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...        [1.4]   \n",
       "2  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...        [1.4]   \n",
       "3  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...        [1.4]   \n",
       "4                                                [0]        [1.4]   \n",
       "\n",
       "  current_subject  \n",
       "0             1.4  \n",
       "1             1.4  \n",
       "2             1.4  \n",
       "3             1.4  \n",
       "4             1.4  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session_dir', 'recording', 'metadata_dir', 'metadata_file',\n",
       "       'description', 'byte_order', 'original_file', 'clockrate',\n",
       "       'trodes_version', 'compile_date', 'compile_time', 'qt_version',\n",
       "       'commit_tag', 'controller_firmware', 'headstage_firmware',\n",
       "       'controller_serialnum', 'headstage_serialnum', 'autosettle', 'smartref',\n",
       "       'gyro', 'accelerometer', 'magnetometer', 'time_offset',\n",
       "       'system_time_at_creation', 'timestamp_at_creation', 'first_timestamp',\n",
       "       'decimation', 'fields', 'data', 'filename', 'direction', 'id',\n",
       "       'display_order', 'clock rate', 'session_path', 'first_dtype_name',\n",
       "       'first_item_data', 'last_dtype_name', 'last_item_data', 'all_subjects',\n",
       "       'current_subject'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPIKEGADGETS_DIN_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_99_0/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/nancy/projects/reward_competition_extention/notebooks/export/01_extract_zscored_lfp.ipynb Cell 64\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/nancy/projects/reward_competition_extention/notebooks/export/01_extract_zscored_lfp.ipynb#Z1110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m SPIKEGADGETS_DIN_DF[\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_99_0/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/spike_interface_0_99_0/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "SPIKEGADGETS_DIN_DF[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "SPIKEGADGETS_DIN_DICT = SPIKEGADGETS_DIN_DF.set_index('recording')[['metadata_file', 'data']].to_dict()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(SPIKEGADGETS_DIN_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_LFP_DF.to_pickle(os.path.join(OUTPUT_DIR, FULL_LFP_TRACES_PKL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_LFP_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF[\"session_path\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "\n",
    "# Assuming 'array' is your numpy array and 'num' is the number of samples in the resampled array\n",
    "resampled_array = resample(array, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import decimate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_SPIKEGADGETS_EXTRACTED_DF[\"all_ch_lfp\"].iloc[0].get_times().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'array' is your numpy array and 'q' is your downsampling factor\n",
    "downsampled_array = decimate(final_SPIKEGADGETS_EXTRACTED_DF[\"first_item_data\"].iloc[0], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_SPIKEGADGETS_EXTRACTED_DF[\"first_item_data\"].apply(lambda x: x[::20]).iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_SPIKEGADGETS_EXTRACTED_DF[\"first_item_data\"].apply(lambda x: x[::20]).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_SPIKEGADGETS_EXTRACTED_DF[\"BLA_lfp_trace\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_SPIKEGADGETS_EXTRACTED_DF[\"first_item_data\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"Stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF = SPIKEGADGETS_EXTRACTED_DF.drop(columns=[ALL_CH_LFP_COL], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF = SPIKEGADGETS_EXTRACTED_DF.drop(columns=[col for col in SPIKEGADGETS_EXTRACTED_DF if SPIKE_INTERFACE_COL in col], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SPIKEGADGETS_EXTRACTED_DF.to_pickle(os.path.join(OUTPUT_DIR, FULL_LFP_TRACES_PKL))"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cf8fe3695d074ee7887fdf6459cbf5ce",
  "kernelspec": {
   "display_name": "spike_interface_0_99_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
